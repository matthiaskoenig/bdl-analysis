hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,1,0.5), add=TRUE)
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7))
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1))
dist1 <- rep(NA, nrow(pred.single))
for (k in 1:nrow(pred.single)){
dist1[k] <- sum( (log(pred.single[k,]+1) - log(BDLsamples$time+1))^2 )
}
dist2 <- rep(NA, nrow(pred.double))
for (k in 1:nrow(pred.double)){
dist2[k] <- sum( (log(pred.double[k,]+1) - log(BDLsamples$time+1))^2 )
}
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1))
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1), xlim=c(0, 0.05))
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist.mean, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0,0,1, 0.5), add=TRUE)
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1), ylim=c(0, 0.05))
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist.mean, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0,0,1, 0.5), add=TRUE)
log_transform <- function(data){
log(data+1)
}
log_transform_back <- function(log_data){
exp(log_data)-1
}
log_transform <- function(data){
log(data+1)
}
log_transform_back <- function(log_data){
exp(log_data)-1
}
# L2 (euclidian) distance measurement on the log transformed data
log_distance <- function(d1, d2){
sum( (log_transform(d1)-log_transform(d2) )^2 )
}
# Transform data to log scale (for comparable time intervals)
log_transform <- function(data){
log(data+1)
}
# Back transformation
log_transform_back <- function(log_data){
exp(log_data)-1
}
# L2 (euclidian) distance measurement on the log transformed data
log_distance <- function(d1, d2){
# sums over all the distances of the samples
sum( (log_transform(d1)-log_transform(d2) )^2 )
}
# distance for all predictions on single factor per cluster
Nsingle <- nrow(pred.single)
dist1 <- rep(NA, Nsingle)
for (k in 1:Nsingle){
dist1[k] <- log_distance(pred.single[k,], BDLsamples$time)
}
# distance for predictions on 2 sampled factors per cluster
Ndouble <- nrow(pred.double)
dist2 <- rep(NA, Ndouble)
for (k in 1:Ndouble){
dist2[k] <- log_distance(pred.double[k,], BDLsamples$time)
}
# distance on mean cluster
dist.mean <- log_distance(pred.mean, BDLsamples$time)
# Plot the distributions of all the distances, i.e. log transformed predictions
# vs. the real time class
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1), ylim=c(0, 0.05))
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist.mean, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0,0,1, 0.5), add=TRUE)
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1), ylim=c(0, 0.05),
xlab="sum( (log(time.predicted+1)-log(time.exp+1))^2 ) ")
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist.mean, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0,0,1, 0.5), add=TRUE)
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1), ylim=c(0, 0.05),
xlab="sum( (log(time.predicted+1)-log(time.exp+1))^2 )", title="Distance between predicted and experimentell time")
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist.mean, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0,0,1, 0.5), add=TRUE)
legend("topright", legend=c("single factor", "double factor", "mean cluster"),
col=c(rgb(0.7, 0.7, 0.7, 1),rgb(1, 0, 0, 0.5),rgb(0, 0, 1, 0.5)),
bty="n", cex=1.0, pch=15)
hist(dist1, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0.7,0.7,0.7, 1), ylim=c(0, 0.05),
xlab="sum( (log(time.predicted+1)-log(time.exp+1))^2 )", main="Distance between predicted and experimentell time")
hist(dist2, breaks=((0:60)*2.5), freq=FALSE, col=rgb(1,0,0, 0.5), add=TRUE)
hist(dist.mean, breaks=((0:60)*2.5), freq=FALSE, col=rgb(0,0,1, 0.5), add=TRUE)
legend("topright", legend=c("single factor", "double factor", "mean cluster"),
col=c(rgb(0.7, 0.7, 0.7, 1),rgb(1, 0, 0, 0.5),rgb(0, 0, 1, 0.5)),
bty="n", cex=1.0, pch=15)
table(sort(dist[dist<15]))
# Transform data to log scale (for comparable time intervals)
log_transform <- function(data){
log(data+1)
}
# Back transformation
log_transform_back <- function(log_data){
exp(log_data)-1
}
pred.mean <- log_transform_back( predict(tree.reg, newdata=treedata.mean, method="anova") )
data.frame(BDLsamples$time, pred.mean)
rsq.rpart(tree.reg) # visualize cross-validation results
?predict.rpart
predict(tree.reg, newdata=treedata.mean, method="anova")
predict(tree.reg, newdata=treedata.mean, type="vector")
predict(tree.reg, newdata=treedata.mean, type="prob")
predict(tree.reg, newdata=treedata.mean, type="matrix")
tree.reg <- rpart(formula=formula.reg, data=treedata.mean, method="anova")
print(tree.reg)
summary(tree.reg)
tree.reg$frame
# this seems like the correct idea, the main question is how the classes are defined & how ROC curves
# are calculated
printcp(tree.reg)
prp(tree.reg, type=0, extra=101, yesno=TRUE)
tree.reg <- rpart(formula=formula.reg, data=treedata.mean, method="anova", control=rpart.control(minsplit=6))
print(tree.reg)
summary(tree.reg)
tree.reg$frame
# this seems like the correct idea, the main question is how the classes are defined & how ROC curves
# are calculated
printcp(tree.reg)
rsq.rpart(tree.reg) # visualize cross-validation results
# text(tree.reg)
# pretty plot
prp(tree.reg, type=0, extra=101, yesno=TRUE)
?rpart
print(tree.reg)
plot(BDLsamples$time, pred.mean)
plot(BDLsamples$time, pred.mean, pch=15, col=rgb(0,0,1, 0.2))
plot(BDLsamples$time, pred.mean, pch=15, col=rgb(0,0,1, 0.2), main="Predicted ~ experimentell time",
xlab="experimentell time [h]", ylab="predicted time (regression tree) [h]")
plot(BDLsamples$time, pred.mean, pch=15, col=rgb(0,0,1, 0.2), main="Regression Tree:\nPredicted ~ experimentell time",
xlab="experimentell time [h]", ylab="predicted time [h]")
abline(a=0, b=1, col="grey")
# mean cluster predictions
pred.mean <- log_transform_back( predict(tree.reg, newdata=treedata.mean, type="vector") )
data.frame(BDLsamples$time, pred.mean)
# plot predicted ~ experimentell
plot(BDLsamples$time, pred.mean, pch=15, col=rgb(0,0,1, 0.2), main="Regression Tree:\nPredicted ~ experimentell time",
xlab="experimentell time [h]", ylab="predicted time [h]")
abline(a=0, b=1, col="grey")
png(filename=file.path(folder, 'decision_tree', "regression_tree.png"), width=2000, height=1000, res=200)
prp(tree.reg, type=0, extra=101, yesno=TRUE)
invisible(dev.off())
prp(tree.reg, type=0, extra=101, yesno=TRUE)
png(filename=file.path(resultsPath, 'decision_tree', "regression_tree.png"), width=2000, height=1000, res=200)
prp(tree.reg, type=0, extra=101, yesno=TRUE)
invisible(dev.off())
prp(tree.reg, type=0, extra=101, yesno=TRUE)
png(filename=file.path(resultsPath, "decision_tree", "predicted_classes.png"), width=1800, height=1000, res=150)
par(mfrow=c(2,4))
for (k in 1:Nt){
# single data
data <- as.vector(pred.single[, ((1:Nr)+Nr*(k-1))])
tab1 <- table(factor(data, levels=node_levels))/length(data)
# single double
data <- as.vector(pred.double[, ((1:Nr)+Nr*(k-1))])
tab2 <- table(factor(data, levels=node_levels))/length(data)
# mean data
data <- as.vector(pred.time[((1:Nr)+Nr*(k-1))])
tab.mean <- table(factor(data, levels=node_levels))/length(data)
# combine data
tab <- rbind(tab1, tab2, tab.mean)
colnames(tab) <- round(as.numeric(colnames(tab)), digits=1)
name <- sprintf("Time after BDL: %sh",
levels(as.factor(BDLsamples$time))[k])
barplot(tab[1,], ylim=c(0,1), col=rgb(0.7,0.7,0.7, 1.0),
main=name, xlab="predicted time class [h]", ylab="fraction of predictions")
barplot(tab[2, ], ylim=c(0,1), col=rgb(1,0,0,0.5) , add=TRUE)
barplot(tab[3, ], ylim=c(0,1), col=rgb(0,0,1,0.5), add=TRUE)
if (k==1){
legend("topright", legend=c("single factor", "double factor", "mean cluster"),
col=c(rgb(0.7, 0.7, 0.7, 1),rgb(1, 0, 0, 0.5),rgb(0, 0, 1, 0.5)),
bty="n", cex=1.0, pch=15)
}
}
par(mfrow=c(1,1))
invisible(dev.off())
png(filename=file.path(resultsPath, "decision_tree", "predicted_classes.png"), width=1800, height=1000, res=150)
plot_predicted_classes()
invisible(dev.off())
plot_predicted_classes()
# Plot of the predicted classes with the decision tree
plot_predicted_classes <- function(){
par(mfrow=c(2,4))
for (k in 1:Nt){
# single data
data <- as.vector(pred.single[, ((1:Nr)+Nr*(k-1))])
tab1 <- table(factor(data, levels=node_levels))/length(data)
# single double
data <- as.vector(pred.double[, ((1:Nr)+Nr*(k-1))])
tab2 <- table(factor(data, levels=node_levels))/length(data)
# mean data
data <- as.vector(pred.time[((1:Nr)+Nr*(k-1))])
tab.mean <- table(factor(data, levels=node_levels))/length(data)
# combine data
tab <- rbind(tab1, tab2, tab.mean)
colnames(tab) <- round(as.numeric(colnames(tab)), digits=1)
name <- sprintf("Time after BDL: %sh",
levels(as.factor(BDLsamples$time))[k])
barplot(tab[1,], ylim=c(0,1), col=rgb(0.7,0.7,0.7, 1.0),
main=name, xlab="predicted time class [h]", ylab="fraction of predictions")
barplot(tab[2, ], ylim=c(0,1), col=rgb(1,0,0,0.5) , add=TRUE)
barplot(tab[3, ], ylim=c(0,1), col=rgb(0,0,1,0.5), add=TRUE)
if (k==1){
legend("topright", legend=c("single factor", "double factor", "mean cluster"),
col=c(rgb(0.7, 0.7, 0.7, 1),rgb(1, 0, 0, 0.5),rgb(0, 0, 1, 0.5)),
bty="n", cex=1.0, pch=15)
}
}
par(mfrow=c(1,1))
}
# barplot of the predicted classes
png(filename=file.path(resultsPath, "decision_tree", "predicted_classes.png"), width=1800, height=1000, res=150)
plot_predicted_classes()
invisible(dev.off())
plot_predicted_classes()
plot_single(S100A)
plot_single("S100A")
plot_single("S100A")
plot_single_factor("S100A")
BDLfactors
plot_single_factor("S100A4")
library(caret)
confusionMatrix(data=pred.class, reference=treedata.mean$class)
formula.mean = paste("class ~ c1 + c2 + c3 + c4 + c5 + c6")
tree.model <- rpart(formula=formula.mean, data=treedata.mean, method="class", control=rpart.control(minsplit=5))
# print information of the tree fit
printcp(tree.model)
print(tree.model)
prp(tree.model, type=0, extra=101, yesno=TRUE) # pretty plot
tree.model <- rpart(formula=formula.mean, data=treedata.mean, method="class", control=rpart.control(minsplit=10))
# print information of the tree fit
printcp(tree.model)
print(tree.model)
prp(tree.model, type=0, extra=101, yesno=TRUE) # pretty plot
pred <- predict(tree.model, newdata=treedata.mean, type="prob")
round(pred, digits=2)

# class prediction with data
pred.class <- predict(tree.model, newdata=treedata.mean, type="class")
pred.class
# evaluation of prediction
# http://stats.stackexchange.com/questions/49416/decision-tree-model-evaluation-for-training-set-vs-testing-set-in-r
library(caret)
confusionMatrix(data=pred.class, reference=treedata.mean$class)
pred <- predict(tree.model, newdata=treedata.mean, type="prob")
round(pred, digits=2)
prp(tree.reg, type=0, extra=101, yesno=TRUE)
pred.reg <- predict(tree.reg, newdata=treedata.mean, type="vector")
confusionMatrix(data=pred.reg, reference=treedata.mean$class)
pred.reg
confusionMatrix(data=pred.class, reference=treedata.mean$class)
pred <- predict(tree.model, newdata=treedata.mean, type="prob")
round(pred, digits=2)
# Barplot for the various time points
# classes via predicted times
node_levels <- levels(as.factor(pred.time))
# This are the predicted classes
node_classes <- round(as.numeric(node_levels), digits=1)
# Plot of the predicted classes with the decision tree
plot_predicted_classes <- function(){
par(mfrow=c(2,4))
for (k in 1:Nt){
# single data
data <- as.vector(pred.single[, ((1:Nr)+Nr*(k-1))])
tab1 <- table(factor(data, levels=node_levels))/length(data)
# single double
data <- as.vector(pred.double[, ((1:Nr)+Nr*(k-1))])
tab2 <- table(factor(data, levels=node_levels))/length(data)
# mean data
data <- as.vector(pred.time[((1:Nr)+Nr*(k-1))])
tab.mean <- table(factor(data, levels=node_levels))/length(data)
# combine data
tab <- rbind(tab1, tab2, tab.mean)
colnames(tab) <- round(as.numeric(colnames(tab)), digits=1)
name <- sprintf("Time after BDL: %sh",
levels(as.factor(BDLsamples$time))[k])
barplot(tab[1,], ylim=c(0,1), col=rgb(0.7,0.7,0.7, 1.0),
main=name, xlab="predicted time class [h]", ylab="fraction of predictions")
barplot(tab[2, ], ylim=c(0,1), col=rgb(1,0,0,0.5) , add=TRUE)
barplot(tab[3, ], ylim=c(0,1), col=rgb(0,0,1,0.5), add=TRUE)
if (k==1){
legend("topright", legend=c("single factor", "double factor", "mean cluster"),
col=c(rgb(0.7, 0.7, 0.7, 1),rgb(1, 0, 0, 0.5),rgb(0, 0, 1, 0.5)),
bty="n", cex=1.0, pch=15)
}
}
par(mfrow=c(1,1))
}
# barplot of the predicted classes
png(filename=file.path(resultsPath, "decision_tree", "predicted_classes.png"), width=1800, height=1000, res=150)
plot_predicted_classes()
invisible(dev.off())
plot_predicted_classes()
tree.reg$frame
pred.mean
node_levels <- levels(as.factor(pred.mean))
pred.mean
node_levels
node_classes
(node_classes[2:length(node_classes)] + node_classes[1:length(node_classes)-1])/2
node_min <- node_classes
node_min[2:length(node_min)] <- node_midpoints
node_midpoints <- (node_classes[2:length(node_classes)] + node_classes[1:length(node_classes)-1])/2
node_min <- node_classes
node_min[2:length(node_min)] <- node_midpoints
node_midpoints <- (node_classes[2:length(node_classes)] + node_classes[1:(length(node_classes)-1)])/2
node_min <- node_classes
node_min[2:length(node_min)] <- node_midpoints
node_max <- node_classes
node_max[1:(length(node_min)-1)] <- node_midpoints
data.frame(node_min, node_classes, node_max)
data.frame(node_classes, node_min, node_max)
plot(BDLsamples$time, pred.mean, pch=15, col=rgb(0,0,1, 0.2), main="Regression Tree:\nPredicted ~ experimentell time",
xlab="experimentell time [h]", ylab="predicted time [h]")
abline(a=0, b=1, col="grey")
node_levels <- levels(as.factor(pred.mean))
# These are the predicted classes
node_classes <- round(as.numeric(node_levels), digits=1)
node_classes
node_mean <- as.numeric(levels(as.factor(pred.mean.log)))
pred.mean.log <- predict(tree.reg, newdata=treedata.mean, type="vector")
# transformation to time in [h]
pred.mean <- log_transform_back( pred.mean.log )
# plot predicted ~ experimentell
plot(BDLsamples$time, pred.mean, pch=15, col=rgb(0,0,1, 0.2), main="Regression Tree:\nPredicted ~ experimentell time",
xlab="experimentell time [h]", ylab="predicted time [h]")
abline(a=0, b=1, col="grey")
node_mean <- as.numeric(levels(as.factor(pred.mean.log)))
node_mean
node_midpoints <- (node_mean[2:length(node_mean)] + node_mean[1:(length(node_mean)-1)])/2
node_mean <- as.numeric(levels(as.factor(pred.mean.log)))
node_midpoints <- (node_mean[2:length(node_mean)] + node_mean[1:(length(node_mean)-1)])/2
# minimum of range
node_min <- node_classes
node_min[2:length(node_min)] <- node_midpoints
# maximum of range
node_max <- node_classes
node_max[1:(length(node_min)-1)] <- node_midpoints
# ranges in log scale
data.frame(node_mean, node_min, node_max)
node_ranges <- data.frame(node_mean, node_min, node_max)
node_mean <- as.numeric(levels(as.factor(pred.mean.log)))
node_midpoints <- (node_mean[2:length(node_mean)] + node_mean[1:(length(node_mean)-1)])/2
# minimum of range
node_min <- node_mean
node_min[2:length(node_min)] <- node_midpoints
# maximum of range
node_max <- node_mean
node_max[1:(length(node_min)-1)] <- node_midpoints
# ranges in log scale
node_ranges <- data.frame(node_mean, node_min, node_max)
node_ranges
node_ranges <- data.frame(mean=log_transform_back(node_mean),
min=log_transform_back(node_min),
max=log_transform_back(node_max))
node_ranges
round(node_ranges, digits=2)
round(node_ranges, digits=1)
rm(ls=list())
rm(list=ls())
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
heatmap.2(t(as.matrix(dtmp)), col=colors(100), scale="row", dendrogram="none", Rowv=NULL, Colv=NULL,
key=TRUE, trace="none", cexRow=0.5, keysize=0.8, density.info="none",
RowSideColors=factorColors,
add.expr=abline(v=v_lines, col="black", lwd=0.5),
main="Heatmap of BDL time course data")
# xlab="sample", ylab="factor")
legend("left",      # location of the legend on the heatmap plot
inset=c(-0.03,0),
legend = rev(f_types), # category labels
col = rev(colorset),  # color key
lty= 1,             # line style
lwd = 10,            # line width
cex = 0.7,
bty="n"
)
# plot subset for further analysis
f_corrplot("cor.ys3", data=cor.ys2, order="hclust", folder=NULL)
plot(cor.ys3)
dev.off()
plot(cor.ys3)
cor.ys3
BDLfactors
colnames(cor.ys3)
idx.accept
levels(BDLfactors$ftype)
BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology")
which(idx.accept && (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology")))
idx.accept && (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology"))
idx.accept & (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology"))
BDLfactors$id[idx.accept & (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology"))]
hist_facs <- BDLfactors$id[idx.accept & (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology"))]
cor.ys3.hist <- cor.ys3[hist_facs, ]
summary(cor.ys3)
hist_facs <- BDLfactors$id[idx.accept & (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology"))]
hist_facs
cor.ys3.hist <- cor.ys3[,hist_facs]
hist_facs
cor.ys3$Ppara
colnames(cor.ys3)
hist_idx <- rep(NA, length(hist_facs))
for (k in 1:length(hist_facs)){
hist_idx[k] <- which(colnames(cor.ys3) == hist_facs[k])
}
hist_idx
cor.ys3[hist_idx, ]
corrplot(data, method="color", type="full",
tl.cex=0.3, tl.col="black", col=col2(10))
data <-  cor.ys3[hist_idx, ]
corrplot(data, method="color", type="full",
tl.cex=0.3, tl.col="black", col=col2(10))
corrplot(data, method="circle", type="full",
tl.cex=0.3, tl.col="black", col=col2(10))
any(data<=0.6)
col.accept <- rep(NA, length(ncol(data)))
col.accept
ncol(data)
col.accept <- rep(NA, length(ncol(data)))
col.accept
col.accept <- rep(NA, times=length(ncol(data)))
col.accept
col.accept <- vector(NA, length(ncol(data)))
col.accept <- rep(NA, ncol(data))
col.accept
for (k in 1:ncol(data)){
col.accept[k] <- (any(data[,k]>=0.6) | any(data[,k]<=0.4)
}
for (k in 1:ncol(data)){
col.accept[k] <- any(data[,k]>=0.6) #  | any(data[,k]<=0.4)
}
col.accept[k] <- any(data[,k]>=0.6) | any(data[,k]<=0.4)
for (k in 1:ncol(data)){
col.accept[k] <- any(data[,k]>=0.6) | any(data[,k]<=0.4)
}
col.accept
for (k in 1:ncol(data)){
col.accept[k] <- any(data[,k]>=0.8) | any(data[,k]<=0.2)
}
col.accept
for (k in 1:ncol(data)){
col.accept[k] <- any(data[,k]>=0.6) | any(data[,k]<=-0.6)
}
col.accept
data[,2]
table(col.accept)
corrplot(data[, col.accept], method="circle", type="full",
tl.cex=0.3, tl.col="black", col=col2(10))
corrplot(data[, col.accept], method="circle", type="full",
tl.cex=0.5, tl.col="black", col=col2(10))
corrplot(data[, col.accept], method="ellipse", type="full",
tl.cex=0.5, tl.col="black", col=col2(10))
corrplot(data[, col.accept], method="number", type="full",
tl.cex=0.5, tl.col="black", col=col2(10))
corrplot(data[, col.accept], method="pie", type="full",
tl.cex=0.5, tl.col="black", col=col2(10))
corrplot(data[, col.accept], method="circle", type="full",
tl.cex=0.7, tl.col="black", col=col2(10))
for (k in 1:ncol(data)){
col.accept[k] <- any(data[,k]>=0.7) | any(data[,k]<=-0.7)
}
table(col.accept)
corrplot(hist_data[, col.accept], method="circle", type="full",
tl.cex=0.7, tl.col="black", col=col2(10))
hist_facs <- BDLfactors$id[idx.accept & (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology"))]
hist_facs
# get the indices of these factors in the correlation matrix
hist_idx <- rep(NA, length(hist_facs))
for (k in 1:length(hist_facs)){
hist_idx[k] <- which(colnames(cor.ys3) == hist_facs[k])
}
hist_data <-  cor.ys3[hist_idx, ] # rows of correlation matrix for the factors
# filter out all the columns where there is no correlation value >=0.7 or <=-0.7,
# i.e. only factors are retained with a absolute correlation coeffient above the
threshold
cor.cutoff = 0.7
col.accept <- rep(NA, ncol(hist_data))
for (k in 1:ncol(data)){
col.accept[k] <- any(hist_data[,k]>=cor.cutoff) | any(hist_data[,k]<=-cor.cutoff)
}
# what is filtered out
table(col.accept)
# plot the subset of the correlation matrix
corrplot(hist_data[, col.accept], method="circle", type="full",
tl.cex=0.7, tl.col="black", col=col2(10))
hist_facs <- BDLfactors$id[idx.accept & (BDLfactors$ftype %in% c("Antibodies", "Biochemistry", "Histology"))]
hist_facs
# get the indices of these factors in the correlation matrix
hist_idx <- rep(NA, length(hist_facs))
for (k in 1:length(hist_facs)){
hist_idx[k] <- which(colnames(cor.ys3) == hist_facs[k])
}
hist_data <-  cor.ys3[hist_idx, ] # rows of correlation matrix for the factors
# filter out all the columns where there is no correlation value >=0.7 or <=-0.7,
# i.e. only factors are retained with a absolute correlation coeffient above the
threshold
cor.cutoff = 0.6
col.accept <- rep(NA, ncol(hist_data))
for (k in 1:ncol(data)){
col.accept[k] <- any(hist_data[,k]>=cor.cutoff) | any(hist_data[,k]<=-cor.cutoff)
}
# what is filtered out
table(col.accept)
# plot the subset of the correlation matrix
corrplot(hist_data[, col.accept], method="circle", type="full",
tl.cex=0.7, tl.col="black", col=col2(10))
corrplot(data[, col.accept], method="pie", type="full",
tl.cex=0.5, tl.col="black", col=col2(10))
corrplot(hist_data[, col.accept], method="circle", type="full",
tl.cex=0.7, tl.col="black", col=col2(10))
packrat::restore(prompt = FALSE)
install.packages("calibrate")
install.packages("pander")
