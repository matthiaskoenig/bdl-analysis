---
title: "Statistical Analysis of Pathobiochemical Signatures in Bile Duct Ligated Mice"
author: '[Matthias Koenig](http://www.charite.de/sysbio/people/koenig) (`r Sys.Date()`)'
output:
  html_document: default
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    toc: yes
  word_document: default
header-includes: \usepackage{graphicx}
---
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{BDL raw data processing}
-->
```{r, options, echo=FALSE}
# set knitr option
# knitr::opts_chunk$set()
knitr::knit_hooks$set(htmlcap = function(before, options, envir) {
  if(!before) {
    paste('<p class="caption">',options$htmlcap,"</p>",sep="")
    }
})
```


# Introduction

This document contains the statistical analysis for the publication *Pathobiochemical signatures of cholestatic liver disease in bile duct ligated mice*.

To better understand the cascade of histological and biochemical alterations after bile duct ligation (BDL), a comprehensive data set of serum markers, histological parameters and transcript profiles was compiled at 8 time points after BDL in mice, comprising different stages of the disease. The analysed data set consists of $N_{r}=5$ repeats ($N_{r}=3$ for the measured antibodies) for $N_{t}=8$ time points denoted by $t_1,..., t_n$ consisting of a total $N_{f}=154$ measured factors (Fluidigm gene expression, antibodies, serum markers, histological measurements).

The main steps of the analysis comprise

* **Explorative data anaysis** and data quality control
* **Dimension reduction via ANOVA**
* **Correlation analysis** based on time course correlation measure
* **Hierarchical clustering** 
* **Decision trees** for prediction

The complete data set, source code and documentation of this analysis is available from  
https://github.com/matthiaskoenig/bdl-analysis .

The following naming conventions are used

* **factor** : one of the measured quantities over time, i.e. either 
    + gene expression of a single gene (e.g. Actb); 
    + one of the biomarkers (e.g. ALT, albumin, bilirubin)
    + one of the histological markers (e.g. BrdU-positive Kupffer cells)
    + one of the antibodies (e.g. CTGF, S100A4)
* **time point** : a single value from the measured time points 0h (control), 6h, 12h, 18h, 30h, 2d, 5d, 14d
* **sample** : one of the $N_{t}*N_{r}=40$ mice, i.e. a one of the repeats for a given time point

# Explorative data analysis
## Data import
In a first step the processed data set is loaded from the `data` folder. The data consists of the time course data for all factors (`BDLdata`), additional information for the factors (`BDLfactors`), the sample definition, i.e. the assignment of sample ids to respective time point and repeat (`BDLsamples`), and a mapping of the Fluidigm (gene) probe ids to UniProt identifiers (`BDLprobes`).  
No other data sets are used in this analysis.

```{r BDLdata, eval=TRUE, strip.white=TRUE}
suppressPackageStartupMessages(library(calibrate))
suppressPackageStartupMessages(library(BDLanalysis))
suppressPackageStartupMessages(library(pander))
# path definition
baseLoc <- system.file(package="BDLanalysis")
extPath <- file.path(baseLoc, "extdata")
resultsPath <- "/home/mkoenig/git/bdl-analysis/results"
# load data
data(BDLdata)
data(BDLsamples)
data(BDLfactors)
data(BDLprobes)
```

In addition to the single measurement data for the factors, the mean data averaged over the $N_{r}$ repeats is used in parts of the correlation analysis. The mean factor data is calculated once at the beginning via
```{r BDLmean}
BDLmean <- bdl_mean_data(BDLdata, BDLsamples)
BDLmean.time <- as.numeric(levels(as.factor(BDLsamples$time)))
```

In total `r ncol(BDLdata)` factors were measured in the BDL study falling in the categories: `r levels(BDLfactors$ftype)`.  
The majority of factors belongs to the 3 fluidigm chips with 47 probes per chip.

An overview of the number of factors per category is given in the following table
```{r factors}
cat_table <- as.data.frame(table(BDLfactors$ftype))
colnames(cat_table) <- c("Category", "Freq")
set.caption(sub(".", " ", "Factors per category", fixed = TRUE))
pander(cat_table)
```

## Data visualization
### Time course of single factors
In a first step overview plots of the raw and mean data for all individual factors are generated. These are available in the `resultsPath/factors` folder
```{r factorPlots, eval=FALSE}
# Visualize all factors
plot_all_factors(path=resultsPath)
```

One example of a single factor plot is depicted below, here for the factor `bilirubin`.
``` {r bilirubin, htmlcap='<b>Figure Single factor</b>: Plot of the raw time course data for a single factor, here for bilirubin. On the left the data is plotted against the time [h], on the right against the different time classes. Individual data points are depecticed in blue with the respective sample number shown next to the data points. The mean averaged of the repeats per time point are depicted in red. Box-and-whisker plots were added with default R parameters of boxwex=0.8, staplewex=0.5, outwex=0.5.'}
plot_single_factor('bilirubin', path=NULL)
```

### Time course of all factors (Heatmap)
In a next step the heatmap of the full data set was generated, i.e. of all time points and repeats. This provides a first overview over the complete data set. Rows correspond to the individual factors (factor order corresponding to the original data set: `GE_ADME`, `GE_Cytokines`, `GE_Fibrosis`, `Biochemistry`, `Histology`, `Antibodies`). Columns correspond to the 40 samples with 5 subsequent samples belonging to one of the 8 time points (with from left to right: `r levels(BDLsamples$time_fac)`). The data is row scaled, i.e. every individual factor is scaled to have mean zero and standard deviation one.
```{r heatmap}
suppressPackageStartupMessages(library("gplots"))
colors <- HeatmapColors() 
dtmp <- BDLdata

# create better row names
rownames(dtmp) <- paste(rownames(BDLsamples), BDLsamples$time_fac, sep=" ")
# create vectors for the horizontal and vertical lines
v_lines <- ((1:8)*5+0.5)
f_types <- c("Antibodies", "Histology", "Biochemistry", "GE_Fibrosis", "GE_Cytokines", "GE_ADME")
f_table <- table(BDLfactors$ftype)
h_lines <- 0.5 + cumsum(f_table[f_types])
# colors for the different data types
library("RColorBrewer")
col2 <- HeatmapColors()
# define colors for type of experimentell data, i.e. factor groups
colorset <- brewer.pal(length(f_types), "Set2")
color.map <- function(factor_id) {return(colorset[ which(f_types==BDLfactors$ftype[which(BDLfactors$id==factor_id)]) ])}
factorColors <- unlist(lapply(BDLfactors$id, color.map))
```

``` {r heatmap2, fig.width=10, fig.height=10, error=TRUE, htmlcap='<b>Figure All factors </b>: Heatmap of the complete data set, i.e. all factors and repeats over time. The data is row scaled, i.e. every individual factor is scaled to have mean zero and standard deviation one, with positive Z-score in blue, negative Z-score in red. The row order is according to the the factor categories, the order within the fluidigm chips according to the order of the probes on the chip. the respective categories are depicted on the left.'}
heatmap.2(t(as.matrix(dtmp)), col=colors(100), scale="row", dendrogram="none", Rowv=NULL, Colv=NULL,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8, density.info="none",
          RowSideColors=factorColors,
          add.expr=abline(v=v_lines, h=h_lines, col="black", lwd=0.5),
          main="Heatmap of BDL time course data")
          # xlab="sample", ylab="factor")
legend("left",      # location of the legend on the heatmap plot
    inset=c(-0.03,0),
    legend = rev(f_types), # category labels
    col = rev(colorset),  # color key
    lty= 1,             # line style
    lwd = 10,            # line width
    cex = 0.7,
    bty="n"
)
```
**Results**: Various patterns are visible in the plotted raw data:

* **Two main classes of response can be observed**. One class with an increase in the early phase up to 6h after BDL (many of the ADME genes fall into this class) and a second class increasing in the later stage after 2-5 days after BDL. Many of the genes on the Cytokines and Fibrosis  chips as well as some of the biochemical, histological and antibody fall in this second class.
* **The individual animals show heterogeneous responses to BDL**. Within one time point the 5 repeats can show very different patterns. For instance at time 6h after BDL 3/5 of the mice show a marked increase in the ADME genes, whereas 2/5 do not show such a marked increase. Another example is the mice sample 27 at time 2d, with a high increase in the genes on the Fibrosis chip, which is not observed in the other 4 samples at time 2d.

## Actb quality control
Actb (Actin, cytoplasmic 1) probes were included on all Fluidigm chips (`GE_ADME`, `GE_Cytokines`, `GE_Fibrosis`) and not used in the normalization of the gene expression data. Hence, ActB can serve as quality control for the technical reproducibility of the Fluidigm chips. If the data is reproducible between chips the pairwise correlation between all individual Actb measurements should have high correlation coefficients close to 1. Plotting the data of the Actb measurements of two chips against each other should lie on a straight line
```{r CheckActB}
# Actb control figure
plot_actb_control <- function(path=NULL){
  if (!is.null(path)){
    png(filename=file.path(path, "Actb_control.png"), width=1600, height=800, res=200)  
  }
  par(mfrow=c(2,3))
  plot_single("Actb")
  plot_single("Actb.x")
  plot_single("Actb.y")
  plot_cor_pair("Actb", "Actb.x", single_plots=FALSE)
  plot_cor_pair("Actb", "Actb.y", single_plots=FALSE)
  plot_cor_pair("Actb.x", "Actb.y", single_plots=FALSE)
  par(mfrow=c(1,1))
  if (!is.null(path)){
    invisible(dev.off())
  }
}
plot_actb_control(path=resultsPath)

# calculate Spearman and Pearson correlation coefficients on N=8*5=40 data points 
actb.spearman <- cor(data.frame(Actb=BDLdata$Actb, 
                                Actb.x=BDLdata$Actb.x, 
                                Actb.y=BDLdata$Actb.y), method="spearman")
actb.pearson <- cor(data.frame(Actb=BDLdata$Actb, 
                               Actb.x=BDLdata$Actb.x, 
                               Actb.y=BDLdata$Actb.y), method="pearson")

# table of correlation coefficients
set.caption(sub(".", " ", "Spearman correlation of Actb controls", fixed = TRUE))
pander(round(actb.spearman, digits=3))
set.caption(sub(".", " ", "Pearson correlation of Actb controls", fixed = TRUE))
pander(round(actb.pearson, digits=3))
```

``` {r fig.width=10, fig.height=7,  htmlcap='<b>Figure Actb control</b>: Correlation plot of the Actb probes from the 3 Fluidigm chips: Actb (fibrosis), Actb.x (ADME), Actb.y (Cytokines). The top row shows the individual time courses, the bottom row the pair wise plot of individual data points.'}
plot_actb_control(path=NULL)
```
**Results**: The Actb Fluidigm gene expression measurements are highly reproducible for the measured chips,  with Spearman as well as Pearson correlation coefficients all > 0.9 for pairwise Actb comparison.

# Dimension reduction via ANOVA
## ANOVA for single factor
A one-way analysis of variance (ANOVA) was applied to reduce the factors to the subset showing significant ($p_{adjusted}< 0.05$) changes during the time course. In its simplest form, ANOVA provides a statistical test of whether or not the means of several groups are equal, and therefore generalizes the t-test to more than two groups, with the groups being the sampled time points. The Holm's procedure was used to correct the p-values for any artificial p-value inflation due to multiple testing. 

For every of the individual factors in the BDL data set an ANOVA was calculated. Dimension reduction of the BDL data set was than performed by filtering out factors which did not significantly changing over time.

The `BDLdata` data set is reshaped into matrix format for the ANOVA calculation, with time points in rows and repeats as columns for every factor. 
```{r BDLmatrix}
BDLmatrices <- bdl_matrix_data(BDLdata, BDLsamples)
```

The following shows the ANOVA calculation for a single factor, here for `bilirubin`. 
``` {r singleanova}
  # example ANOVA for one factor
  mat.anova <- t(BDLmatrices[['bilirubin']])
  colnames(mat.anova) <- levels(BDLsamples$time_fac)
  
  # concatenate the data rows of df1 into a single vector r .
  r = c(t(as.matrix(mat.anova)))  # response data 
  
  # assign new variables for the treatment levels and number of observations.
  f = levels(BDLsamples$time_fac)   # treatment levels 
  k = 8                          # number of treatment levels 
  n = 5                          # observations per treatment 
  
  # create a vector of treatment factors that corresponds to each element of r in step 3 with the gl function.
  tm <- gl(k, 1, n*k, factor(f))   # matching treatments 
  
  # apply the function aov to a formula that describes the response r by the treatment factor tm.
  # fit an analysis of variance model
  av <- aov(r ~ tm) 
  
  # print out the ANOVA table with the summary function. 
  summary(av)
  # print the corresponding p-value
  p.value <- summary(av)[[1]][["Pr(>F)"]][[1]]

  # show data matrix
  print(mat.anova)
```

## ANOVA for all factors
Analog to the single factor ANOVA, the ANOVA is performed on all the factors. Hereby, a multitude of tests are performed, namely an ANOVA for every single factor. Consequently, the reported p-values of the ANOVA have to be adjusted via multiple testing procedures. Using the p.adjust function which given a set of p-values, returns p-values adjusted using one of several methods. The Bonferroni, Holm, Hochberg, Hommel are designed to give strong control of the family-wise error rate. We used the Holm's method for adjustment (*Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics 6, 65-70.*).


```{r ANOVA}
# Calculation of ANOVA for all factors
df.anova <- all_factor_anova()
df.anova$sig <- sapply(df.anova$p.value, significant_code)  # add significant codes

df.anova$p.holm <- p.adjust(df.anova$p.value, method ="holm" , n = length(df.anova$p.value))
df.anova$sig.holm <- sapply(df.anova$p.holm, significant_code) 

# order factors by adjusted p-values
df.anova.ordered <- df.anova[with(df.anova, order(p.holm)), ]
df.anova.ordered

# save results
write.table(df.anova.ordered, file=file.path(resultsPath, 'BDLanova.csv'), sep="\t", quote=FALSE)
BDLanova <- df.anova
save(df.anova, file=file.path(resultsPath, "BDLanova.Rdata"))
```

## Filter factors
The factors are filtered based on the respective acceptance level, with the cutoff for the adjusted p-value being $p_{accept}$, i.e. all factors with a ANOVA with $p_{adjusted} \ge p_{accept}$ are filtered out. The filtered raw data is available as `BDLdata.fil`, the filtered mean data set as `BDLmean.fil`. All subsequent analyses are performed on the filtered data set, which is depicted in the following heatmap
``` {r filter}
p.accept = 0.05  # acceptance level
idx.accept = (df.anova$p.holm < p.accept)  # accepted subset
# subset of filtered data
BDLdata.fil <- BDLdata[, idx.accept]
BDLmean.fil <- BDLdata[, idx.accept]

# accepted
table(df.anova$p.holm<p.accept)  # 64 rejected / 90 accepted (adjusted)

# which factors were accepted in the various categories
fil_tab <- data.frame(
  table(BDLfactors$ftype[idx.accept]),
  table(BDLfactors$ftype),
  round(table(BDLfactors$ftype[idx.accept])/table(BDLfactors$ftype), 2)
)
fil_tab <- fil_tab[, c('Var1', 'Freq', 'Freq.1', 'Freq.2')]
names(fil_tab) <- c('Category', 'Accepted', 'All', 'Percent')
fil_tab

```
Almost all `Cytokines` genes are retained in the data set whereas many of the `ADME` and `Fibrosis` genes are filtered.

### Heatmap of filtered time course data
The heatmap of the filtered raw data is depicted below
``` {r heatmapFiltered}
# prepare data with row names
dtmp <- BDLdata.fil
rownames(dtmp) <- paste(rownames(BDLsamples), BDLsamples$time_fac, sep=" ")
# create vectors for the horizontal and vertical lines
v_lines <- ((1:8)*5+0.5)
f_types <- c("Antibodies", "Histology", "Biochemistry", "GE_Fibrosis", "GE_Cytokines", "GE_ADME")

# define colors for categories
colorset <- brewer.pal(length(f_types), "Set2")
color.map <- function(factor_id) {return(colorset[ which(f_types==BDLfactors$ftype[which(BDLfactors$id==factor_id)]) ])}
factorColors <- unlist(lapply(colnames(BDLdata.fil), color.map))
```

``` {r heatmap_filtered, fig.width=10, fig.height=10, error=TRUE, htmlcap='<b>Figure Heatmap ANOVA:</b> Plot of ANOVA filtered data set.'}
heatmap.2(t(as.matrix(dtmp)), col=colors(100), scale="row", dendrogram="none", Rowv=NULL, Colv=NULL,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8, density.info="none",
          RowSideColors=factorColors,
          add.expr=abline(v=v_lines, col="black", lwd=0.5),
          main="Heatmap of BDL time course data")
          # xlab="sample", ylab="factor")
legend("left",      # location of the legend on the heatmap plot
    inset=c(-0.03,0),
    legend = rev(f_types), # category labels
    col = rev(colorset),  # color key
    lty= 1,             # line style
    lwd = 10,            # line width
    cex = 0.7,
    bty="n"
)
```


# Correlation analysis
For the correlation analysis between factors and the subsequent cluster analysis a correlation measure for time series data {Son2008} in combination with Complete-Linkage hierarchical clustering was used. This combination of methods provided the best enrichments on gene-expression time-series in a recent comparisons of methods {Jaskowiak2014, Jaskowiak2013} testing various correlation measures and clustering algorithms. 

The calculation of correlation coefficients between factors i and j ($i,j=1, ...,N_p$) was performed using the slightly modified correlation coefficient based similarity measure developed for clustering of time-course data ($Y_{i,j}^{S2}$ and $Y_{i,j}^{R2}$) {Son2008}. $Y_{i,j}^{S2}$ and $Y_{i,j}^{R2}$ are linear combinations of (i) a classical correlation part based on Spearman correlation $S_{i,j}^{*}$ in case of $Y_{i,j}^{S2}$ or Pearson $R_{i,j}^{*}$ in case of $Y_{i,j}^{R2}$, (ii) a component $A_{i,j}^{*}$ accounting for the similarity in changes between two time courses, (iii) a component $M_{i,j}^{*}$ comparing the location of minimum and maximum values of the time course (see {Son2008} for definitions)
$$Y_{i,j}^{S2} = w_1 S_{i,j}^{*} + w_2 A_{i,j}^{*} + w_3 M_{i,j}^{*}$$
$$Y_{i,j}^{R2} = w_1 R_{i,j}^{*} + w_2 A_{i,j}^{*} + w_3 M_{i,j}^{*}$$
$R_{i,j}^{*}$ and $S_{i,j}^{*}$ are hereby calculated on the individual data points for the factors i and j, $A_{i,j}^{*}$ and $M_{i,j}^{*}$ on the mean time courses averaged over the $N_r$ repeated measurements. Throughout the analysis the following weights were used $w_1=0.5$, $w_2=0.3$, $w_3=0.2$.

In the calculation of the change component we used a Spearman correlation based measure ($A^{**}$) instead of the originally proposed Pearson measure ($A^{*}$) resulting in the correlation scores $Y_{i,j}^{S3}$ and $Y_{i,j}^{S3}$
$$Y_{i,j}^{S3} = w_1 S_{i,j}^{*} + w_2 A_{i,j}^{**} + w_3 M_{i,j}^{*}$$
$$Y_{i,j}^{R3} = w_1 R_{i,j}^{*} + w_2 A_{i,j}^{**} + w_3 M_{i,j}^{*}$$
Herein, $A_{i,j}^{**}$ calculates the correlation of changes between factors i and j based on Spearman correlation analog $A_{i,j}^{*}$ as
$$A_{i,j}^{**}=(S(d_i,d_j)+1)/2$$
$$A_{i,j}^{*}=(R(d_i,d_j)+1)/2$$
The reason for this adaption was that initial analysis showed a strong dependency of the change components on outliers.

All calculated correlation scores $Y^{S}$ and $Y^{R}$ are transformed from [0, 1] to [-1, 1] via
$$Y_{norm}^{S} = 2(Y^{S}-0.5)$$
$$Y_{norm}^{R} = 2(Y^{R}-0.5)$$

In addition to the used $Y^{S}$ and $Y^{R}$ correlation scores Pearson (R) and Spearman (S) correlations were calculated for comparison. 

## Pearson & Spearman correlation
In a first step Pearson $R_{i,j}$ and Spearman $S_{i,j}$ correlation was calculated for the filtered factors. 
Heatmaps of the resulting correlation matrices are depicted below with reordering of factors based on hierarchical clustering with Complete Linkage.

``` {r correlation}
# correlation matrix
suppressPackageStartupMessages(require(corrplot))
cor.pearson <- cor(BDLdata.fil, method="pearson", use="pairwise.complete.obs")
cor.spearman <- cor(BDLdata.fil, method="spearman", use="pairwise.complete.obs")

# Helper function for creating correlation plot and saving to results folder.
# TODO: update the corrplot to use the heatmap.2
f_corrplot <- function(name, data, order, folder="../results",
                       width=1600, height=1600, res=200){
  # TODO: create the plot using the heatmap.2 with color based on histopathology
  fname <- sprintf("%s_%s.png", name, order)
  col2 <- HeatmapColors()
  if (!is.null(folder)){
    png(filename=file.path(folder, "correlation", fname), width=width, height=height, res=res)  
  }
  corrplot(data, order=order, hclust.method="complete", method="color", type="full", 
           tl.cex=0.3, tl.col="black", col=col2(10))
  if (!is.null(folder)){
    invisible(dev.off())  
  }
}

# Spearman
f_corrplot("cor.spearman", data=cor.spearman, order="original", folder=resultsPath)
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=resultsPath)
# Pearson
f_corrplot("cor.pearson", data=cor.pearson, order="original", folder=resultsPath)
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=resultsPath)
```

```{r}
# Pearson correlation with hierarchical clustering
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=NULL)
```

```{r}
# Spearman correlation with hierarchical clustering
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=NULL)
```

The pearson correlation is highly sensitive to outliers (correlation between factors, but also in the changes between time points). 


## YS & YR correlation
Here, the time-course based correlation measurements $Y^{S1}$, $Y^{S2}$, $Y^{S3}$, $Y^{R1}$, $Y^{R2}$ and $Y^{R3}$ are calculated for the factors in the filtered BDL data set. To create the correlation matrix all pairwise correlations between all factors are calculated.

``` {r ys1_yr1}
# calculate ys1, yr1 on mean data, i.e. correlation part (S*), slope part (A) and min/max part (M) are all calculated on the mean data of all repeats.
# w <- list(w1=0.5, w2=0.25, w3=0.25)
w <- list(w1=0.5, w2=0.3, w3=0.2)

# calculate the YSR component matrices on the filtered data set (A, A*, A**, M, M*)
# all components are calculated on the mean data
ysr.res <- ysr.matrices(BDLmean.fil, BDLmean.time, use="pairwise.complete.obs")

# Pearson & spearman correlation on individual data points
cor.S_star <- ( cor(BDLdata.fil, method="spearman", use="pairwise.complete.obs") + 1 )/2
cor.R_star <- ( cor(BDLdata.fil, method="pearson", use="pairwise.complete.obs") + 1 )/2

# Calculate the ys(1,2,3) and yr(1,2,3) with single time point correlation for
# Spearman, respectively Pearson (instead of mean)
# Takes the individual correlation, slope and min/max components for the respective
# score parts and weights with the provided weighting factors (w1,w2,w3)
cor.ys1.raw <- w$w1*cor.S_star + w$w2*ysr.res$A       + w$w3*ysr.res$M
cor.ys2.raw <- w$w1*cor.S_star + w$w2*ysr.res$A_star  + w$w3*ysr.res$M_star
cor.yr1.raw <- w$w1*cor.R_star + w$w2*ysr.res$A       + w$w3*ysr.res$M
cor.yr2.raw <- w$w1*cor.R_star + w$w2*ysr.res$A_star  + w$w3*ysr.res$M_star
# extended
cor.ys3.raw <- w$w1*cor.S_star + w$w2*ysr.res$A_star2 + w$w3*ysr.res$M_star
cor.yr3.raw <- w$w1*cor.R_star + w$w2*ysr.res$A_star2 + w$w3*ysr.res$M_star 

# scaling of correlation coefficient in interval [-1,1]
cor.ys1 <- 2*(cor.ys1.raw-0.5)
cor.ys2 <- 2*(cor.ys2.raw-0.5)
cor.ys3 <- 2*(cor.ys3.raw-0.5)
cor.yr1 <- 2*(cor.yr1.raw-0.5)
cor.yr2 <- 2*(cor.yr2.raw-0.5)
cor.yr3 <- 2*(cor.yr3.raw-0.5)

# plot subset for further analysis
f_corrplot("cor.ys3", data=cor.ys2, order="hclust", folder=NULL)

# create correlation plot on disk
f_corrplot("cor.ys1", data=cor.ys1, order="hclust", folder=resultsPath)
f_corrplot("cor.ys2", data=cor.ys2, order="hclust", folder=resultsPath)
f_corrplot("cor.ys3", data=cor.ys3, order="hclust", folder=resultsPath)
f_corrplot("cor.yr1", data=cor.yr1, order="hclust", folder=resultsPath)
f_corrplot("cor.yr2", data=cor.yr2, order="hclust", folder=resultsPath)
f_corrplot("cor.yr3", data=cor.yr3, order="hclust", folder=resultsPath)
```
The further analysis is performed using $ $


# Hierarchical clustering
Based on the calculated correlation matrices between factors hierarchical clustering is performed on the correlation matrices using complete linkage (hclust).

The next step of dimension reduction is clustering of the correlation matrix. This groups the factors into sets with the correlation within sets being larger than between sets. This effectivly finds groups of factors which have similar time courses.

The hclust function in R was used for clustering with complete linkage method for hierarchical clustering. This particular clustering method defines the cluster distance between two clusters to be the maximum distance between their individual components.

An overview of the clusters is given in the `results/cluster` folder.

``` {r}
# Plot the clusters
suppressPackageStartupMessages(require('matrixStats'))

# mean plots for clusters 
f_normalize_centering <- function(a){
  a.norm <- (a - mean(a))/(max(a, na.rm=TRUE) - min(a, na.rm=TRUE))
  return(a.norm)
}

# plot of mean clusters
plot_clusters <- function(method, folder=NULL){  
  # create the figure
  if (!is.null(folder)){
    fname <- sprintf("%s_cluster_overview.png", method)
    path <- file.path(folder, 'cluster', fname)
    png(filename=path, width=1600, height=1600, res=200)
  }
  # par(mfrow=c(ceiling(sqrt(Ngroups)),ceiling(sqrt(Ngroups))))
  par(mfrow=c(2,3))
  
  steps <- 1:8 # time points
    for (k in 1:Ngroups){
      g <- groups.hc.order[groups.hc.order==k]
      N <- ceiling(sqrt(length(g)))
      dgroup <- BDLmean[names(g)]
    
      # centralize and normalize columns, i.e. the individual factors for comparison
      dgroup.norm <- apply(dgroup, 2, f_normalize_centering)
      
      # mean and sd for timepoints 
      g.mean <- rowMeans(dgroup.norm)
      g.sd <- rowSds(dgroup.norm)   # apply(dgroup.norm, 2, sd)
      
      # plot sd range
      plot(1, type="n", xlab="", ylab="", xlim=c(1, 8), ylim=c(-1, 1), main=sprintf("%s : Cluster %s", method, k))
      polygon(c(steps, rev(steps)), c(g.mean+g.sd, rev(g.mean-g.sd)),
              col = rgb(0.5,0.5,0.5,0.5), border = NA)
      
      # individual data
      for (name in names(g)){
        points(steps, dgroup.norm[, name], pch=16, col="black")
        lines(steps, dgroup.norm[, name], col=rgb(0.5,0.5,0.5, 0.8), lwd=1)
      }
      # mean over factors in cluster
      lines(steps, g.mean, col="blue", lwd=2)
    }
    par(mfrow=c(1,1))
  if (!is.null(folder)){
    invisible(dev.off())
  }
}

# Plot individual time courses in cluster
plot_clusters_items <- function(folder=NULL){
  for (k in 1:Ngroups){
    if (!is.null(folder)){
      fname <- sprintf("%s_cluster_%s.png", method, k)
      path <- file.path(folder, 'cluster', fname)
      png(filename=path, width=3000, height=3000, res=200)  
    }
    g <- groups.hc.order[groups.hc.order==k]
    N <- ceiling(sqrt(length(g)))
    par(mfrow=c(N,N))
    for (name in names(g)){
      plot_single(name_A=name) 
    }
    par(mfrow=c(1,1))  
    if (!is.null(folder)){
      invisible(dev.off())
    }
  }  
}

correlation_matrix_for_method <- function(method){
   if (identical(method, "ys1")){
    cor.cluster <- cor.ys1  
  }else if (identical(method, "ys2")){
    cor.cluster <- cor.ys2
  }else if (identical(method, "ys3")){
    cor.cluster <- cor.ys3
  }else if (identical(method, "yr1")){
    cor.cluster <- cor.yr1
  }else if (identical(method, "yr2")){
    cor.cluster <- cor.yr2
  }else if (identical(method, "yr3")){
    cor.cluster <- cor.yr3
  }else if (identical(method, "pearson")){
    cor.cluster <- cor.pearson
  }else if (identical(method, "spearman")){
    cor.cluster <- cor.spearman
  }  
  return(cor.cluster)
}

# apply hirarchical clustering based on selected correlation measure
cluster_methods <- c("pearson", "spearman", "ys1", "ys2", "ys3", "yr1", "yr2", "yr3")
Ngroups <-  6

for (method in cluster_methods){
  cor.cluster <- correlation_matrix_for_method(method)
  
  # perform hierarchical clustering and cut into Ngroups clusters.
  hc <- hclust(dist(cor.cluster)) 
  groups <- cutree(hc, k=Ngroups)
  groups.hc.order <- groups[hc$order]
  
  # plot cluster overview in report
  if (identical(method, "ys3")){
    plot_clusters(method=method, folder=NULL)  
  }
  # plot all clusters on disk
  plot_clusters(method=method, folder=resultsPath) 

  # plot individual factors in clusters on disk
  plot_clusters_items(folder=resultsPath)
}
```

TODO: overview over the cluster size and content




Display the clusters with the heatmap
``` {r heatmap_ys3, fig.width=10, fig.height=10, error=TRUE, htmlcap='<b>Figure Heatmap Cluster:</b> Plot of ANOVA filtered data set.'}

method <- 'ys3'
cor.cluster <- correlation_matrix_for_method(method)

col2 <- HeatmapColors()
hc <- hclust(dist(cor.cluster)) 
# get cluster IDs for the groups
groups <- cutree(hc, k=Ngroups)

# define colors for the Ngroups clusters

# display.brewer.all()
colorset <- brewer.pal(Ngroups, "Set1")
color.map <- function(cluster_id) {return(colorset[cluster_id])}
clusterColors <- unlist(lapply(groups, color.map))

heatmap.2(cor.cluster, col=col2(100), scale="none",
          key=TRUE, symkey=FALSE, trace="none", cexRow=0.5, cexCol=0.5,
          main=method,
          density.info="none", dendrogram="column", Rowv=as.dendrogram(hc), Colv=as.dendrogram(hc), keysize=0.8,
          ColSideColors=clusterColors, revC=TRUE)
```


Overview of the individual time courses in the clusters
```{r, eval=FALSE}
# TODO
```

# Decision Trees
The decision trees are based on the clusters. This has the large advantage to be not dependent on a single factor, but it uses the combined information available by multiple factors. Consequently, the decision tree is applicable to any subset of factors measured. 

Example decision tree on the full dataset with `rpart` and `rpart.plot`
``` {r}
# Standard decision trees on the full predictor set
require(rpart)
require(rpart.plot)

# add the class label to the predictors (time points/period are used as classes)
treedata <- BDLdata.fil
treedata$class <- BDLsamples$time_fac
head(treedata)

# create formula for tree classification
# full formula using all predictors of filtered data
formula.fil = paste("class ~ ", paste(colnames(BDLdata.fil), sep="", collapse=" + "), sep="")

# fit the tree with classification
# tree.fit <- rpart(formula=f, data=treedata, method="class", control=rpart.control(minsplit=1)) 
tree.fit <- rpart(formula=formula.fil, data=treedata, method="class", control=rpart.control(minsplit=5)) 
# print information of the tree fit
printcp(tree.fit)
print(tree.fit)
# plot the tree
plot(tree.fit)
text(tree.fit)
# pretty plot
prp(tree.fit, type=0, extra=101, yesno=TRUE)
```

Now perform the tree fit on the clustered data set.
```{r}
# get the hierarchical clusters for ys3
method <- "ys3"
cor.cluster <- correlation_matrix_for_method(method)
# perform hierarchical clustering and cut into Ngroups clusters.
hc <- hclust(dist(cor.cluster)) 
groups <- cutree(hc, k=Ngroups)
groups.hc.order <- groups[hc$order]
plot(hc)

group_table <- table(groups)
print(group_table)
# Number of combinations
prod(group_table)

```

``` {r}
# Create the cluster data set

# data has to be normalized analog to the plotted clusters

BDLtree <- as.data.frame(apply(BDLdata.fil, 2, f_normalize_centering))
# TODO: fix bug NA for antibodies (mean -> na.rm)
head(BDLtree)
plot(BDLsamples$time, BDLtree$bilirubin)


# [1] Mean cluster
Nt <- 8
Nr <- 5
na.vec <- rep(NA, Nt*Nr)
treedata.mean <- data.frame(class=na.vec, c1=na.vec, c2=na.vec, c3=na.vec, c4=na.vec, c5=na.vec, c6=na.vec)
treedata.mean$class <- BDLsamples$time_fac

# for every sample
for (ks in 1:(Nt*Nr)){
  # create the mean over the cluster
  for (kgroup in 1:Ngroups){
    # get the factors in the cluster
    factors <- names(groups[groups==kgroup])
    treedata.mean[ks, (kgroup+1)] <- mean(as.numeric(BDLtree[ks, factors]), na.rm=TRUE)
  }
}
print(treedata.mean)

# fit the tree with classification
formula.mean = paste("class ~ c1 + c2 + c3 + c4 + c5 + c6")
tree.fit <- rpart(formula=formula.mean, data=treedata.mean, method="class", control=rpart.control(minsplit=5)) 

# print information of the tree fit
printcp(tree.fit)
print(tree.fit)
# pretty plot
prp(tree.fit, type=0, extra=101, yesno=TRUE)

# fit the tree with regression (on the log)
treedata.reg <- treedata.mean
treedata.reg$regvalue <- log(BDLsamples$time+1)
head(treedata.reg)
treedata.reg
formula.fil.reg = paste("regvalue ~ c1 + c2 + c3 + c4 + c5 + c6")

tree.reg <- rpart(formula=formula.fil.reg, data=treedata.reg, method="anova", control=rpart.control(minsplit=6, minbucket=2, cp=-1))
tree.reg <- rpart(formula=formula.fil.reg, data=treedata.reg, method="anova", control=rpart.control(minsplit=6, minbucket=2))

printcp(tree.reg)
text(tree.reg)
prp(tree.reg, type=0, extra=101, yesno=TRUE)


# [2] Single factor from cluster
Ndata <- prod(group_table) * 5  # number of group combinations * number repeats
na.vec <- rep(NA, )
treedata.single <- data.frame(class=na.vec, c1=na.vec, c2=na.vec, c3=na.vec, c4=na.vec, c5=na.vec, c6=na.vec, 
                       c1.id=na.vec, c2.id=na.vec, c3.id=na.vec, c4.id=na.vec, c5.id=na.vec, c6.id=na.vec)

```

