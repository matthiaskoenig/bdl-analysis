---
title: "Statistical Analysis of Pathobiochemical Signatures in Bile Duct Ligated Mice"
author: '[Matthias Koenig](http://www.charite.de/sysbio/people/koenig) (`r Sys.Date()`)'
output:
  html_document: default
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    toc: yes
  word_document: default
header-includes: \usepackage{graphicx}
---
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{BDL raw data processing}
-->
```{r, options, echo=FALSE}
# set knitr option
# knitr::opts_chunk$set()
knitr::knit_hooks$set(htmlcap = function(before, options, envir) {
  if(!before) {
    paste('<p class="caption">',options$htmlcap,"</p>",sep="")
    }
})
```


# Introduction

This document contains the statistical analysis for the publication *Pathobiochemical signatures of cholestatic liver disease in bile duct ligated mice*.

To better understand the cascade of histological and biochemical alterations after bile duct ligation (BDL), a comprehensive data set of serum markers, histological parameters and transcript profiles was compiled at 8 time points after BDL in mice, comprising different stages of the disease. The analysed data set consists of $N_{r}=5$ repeats ($N_{r}=3$ for the measured antibodies) for $N_{t}=8$ time points denoted by $t_1,..., t_n$ consisting of a total $N_{f}=154$ measured factors (Fluidigm gene expression, antibodies, serum markers, histological measurements).

The main steps of the analysis comprise

* **Explorative data anaysis** and data quality control
* **Dimension reduction via ANOVA**
* **Correlation analysis** based on time course correlation measure
* **Hierarchical clustering** 
* **Decision trees** for prediction

The complete data set, source code and documentation for reproducing this analysis is available from  
https://github.com/matthiaskoenig/bdl-analysis .

# Explorative data analysis
## Data import
In a first step the processed data set is loaded from the `data` folder. The data consists of the time course data for all factors (`BDLdata`), additional information for the factors (`BDLfactors`), the sample definition, i.e. the assignment of sample ids to respective time point and repeat (`BDLsamples`), and a mapping of the Fluidigm (gene) probe ids to UniProt identifiers (`BDLprobes`).  
No other data sets are used in this analysis.

```{r BDLdata, eval=TRUE, strip.white=TRUE}
suppressPackageStartupMessages(library("calibrate"))
suppressPackageStartupMessages(library('BDLanalysis'))
# path definition
baseLoc <- system.file(package="BDLanalysis")
extPath <- file.path(baseLoc, "extdata")
resultsPath <- "/home/mkoenig/git/bdl-analysis/results"
# load data
data(BDLdata)
data(BDLsamples)
data(BDLfactors)
data(BDLprobes)
```

In addition to the single measurement data for the factors, the mean data averaged over the $N_{r}$ repeats is used in parts of the correlation analysis. The mean factor data is calculated once at the beginning via
```{r BDLmean}
BDLmean <- bdl_mean_data(BDLdata, BDLsamples)
BDLmean.time <- as.numeric(levels(as.factor(BDLsamples$time)))
```

In total `r ncol(BDLdata)` factors were measured in the BDL study falling in the categories: `r levels(BDLfactors$ftype)`, with the majority of the factors being from the 3 fluidigm chips with respectively 47 probes for ADME, Cytokines and Fibrosis
```{r factors}
table(BDLfactors$ftype)
```

## Data visualization
In a first step overview plots of the raw and mean data for all factors were generated. These are available in the `resultsPath/factors` folder
```{r factorPlots, eval=FALSE}
# Visualize single factor
plot_single_factor(name=colnames(BDLdata)[2])
# Visualize all factors
plot_all_factors(path=resultsPath)
```

The example plot for `bilirubin` is depicted below
``` {r bilirubin, htmlcap='<b>Figure bilirubin:</b> Example plot of raw time course data for factor bilirubin. On the left the data is plotted against the time [h], on the right against the different time classes.'}
plot_single_factor('bilirubin', path =NULL)
```

### Time course heatmap of factors
In a next step the heatmap of the full data set was generated, i.e. of all time points and repeats. This provides a first overview over the complete data set. Rows correspond to the individual factors (factor order corresponding to the original data set: `GE_ADME`, `GE_Cytokines`, `GE_Fibrosis`, `Biochemistry`, `Histology`, `Antibodies`). Columns correspond to the 40 samples with 5 subsequent samples belonging to one of the 8 time points (with from left to right: `r levels(BDLsamples$time_fac)`). The data is row scaled, i.e. every individual factor is scaled to have mean zero and standard deviation one.
```{r heatmap}
suppressPackageStartupMessages(library("gplots"))
colors <- HeatmapColors() 
dtmp <- BDLdata

# create better row names
rownames(dtmp) <- paste(rownames(BDLsamples), BDLsamples$time_fac, sep=" ")
# create vectors for the horizontal and vertical lines
v_lines <- ((1:8)*5+0.5)
f_types <- c("Antibodies", "Histology", "Biochemistry", "GE_Fibrosis", "GE_Cytokines", "GE_ADME")
f_table <- table(BDLfactors$ftype)
h_lines <- 0.5 + cumsum(f_table[f_types])
# colors for the different data types
library("RColorBrewer")
col2 <- HeatmapColors()
# define colors for type of experimentell data, i.e. factor groups
colorset <- brewer.pal(length(f_types), "Set2")
color.map <- function(factor_id) {return(colorset[ which(f_types==BDLfactors$ftype[which(BDLfactors$id==factor_id)]) ])}
factorColors <- unlist(lapply(BDLfactors$id, color.map))
```

``` {r heatmap2, fig.width=10, fig.height=10, error=TRUE, htmlcap='<b>Figure Heatmap 1:</b> Plot of the complete data set, i.e. all factors and repeats.'}
heatmap.2(t(as.matrix(dtmp)), col=colors(100), scale="row", dendrogram="none", Rowv=NULL, Colv=NULL,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8, density.info="none",
          RowSideColors=factorColors,
          add.expr=abline(v=v_lines, h=h_lines, col="black", lwd=0.5),
          main="Heatmap of BDL time course data")
          # xlab="sample", ylab="factor")
legend("left",      # location of the legend on the heatmap plot
    inset=c(-0.03,0),
    legend = rev(f_types), # category labels
    col = rev(colorset),  # color key
    lty= 1,             # line style
    lwd = 10,            # line width
    cex = 0.7,
    bty="n"
)
```
**Results**: Various time course patterns are visible in the raw data. For instance many of the ADME genes seem to be increased in the early phase until 6h decrease later on. On the other hand the Cytokines and Fibrosis genes as well as many of the biochemical, histological and antibody markers are increased in the later stage after 2-5 days.

## Actb quality control
Actb (Actin, cytoplasmic 1) probes were included on all Fluidigm chips (`GE_ADME`, `GE_Cytokines`, `GE_Fibrosis`) and not used in the normalization of the gene expression data. Hence, ActB can serve as quality control for the technical reproducibility of the Fluidigm chips. If the data is reproducible between chips the pairwise correlation between all individual Actb measurements should have high correlation coefficients close to 1. Plotting the data of the Actb measurements of two chips against each other should lie on a straight line
```{r CheckActB}
# Actb control figure
plot_actb_control <- function(path=NULL){
  if (!is.null(path)){
    png(filename=file.path(path, "Actb_control.png"), width=1600, height=800, res=200)  
  }
  par(mfrow=c(2,3))
  plot_single("Actb")
  plot_single("Actb.x")
  plot_single("Actb.y")
  plot_cor_pair("Actb", "Actb.x", single_plots=FALSE)
  plot_cor_pair("Actb", "Actb.y", single_plots=FALSE)
  plot_cor_pair("Actb.x", "Actb.y", single_plots=FALSE)
  par(mfrow=c(1,1))
  if (!is.null(path)){
    invisible(dev.off())
  }
}
plot_actb_control(path=resultsPath)

# calculate Spearman and Pearson correlation coefficients on N=8*5=40 data points 
actb.spearman <- cor(data.frame(Actb=BDLdata$Actb, 
                                Actb.x=BDLdata$Actb.x, 
                                Actb.y=BDLdata$Actb.y), method="spearman")
actb.pearson <- cor(data.frame(Actb=BDLdata$Actb, 
                               Actb.x=BDLdata$Actb.x, 
                               Actb.y=BDLdata$Actb.y), method="pearson")
# knitr table
# knitr::kable(actb.spearman, digits=3)
# knitr::kable(actb.pearson, digits=3)
# pander table
suppressPackageStartupMessages(library(pander))
set.caption(sub(".", " ", "Spearman correlation of Actb controls", fixed = TRUE))
pander(round(actb.spearman, digits=3))
set.caption(sub(".", " ", "Pearson correlation of Actb controls", fixed = TRUE))
pander(round(actb.pearson, digits=3))
```

``` {r fig.width=10, fig.height=7,  htmlcap='<b>Figure Actb</b>: Correlation plot of the Actb'}
plot_actb_control(path=NULL)
```
**Results**: The Actb Fluidigm gene expression measurements are highly reproducible for the measured chips,  with Spearman as well as Pearson correlation coefficients all > 0.9 for pairwise Actb comparison.

# Dimension reduction via ANOVA
## ANOVA for single factor
A one-way analysis of variance (ANOVA) was applied to reduce the factors to the subset showing significant ($p_{adjusted}< 0.05$) changes during the time course. In its simplest form, ANOVA provides a statistical test of whether or not the means of several groups are equal, and therefore generalizes the t-test to more than two groups, with the groups being the sampled time points. The Holm's procedure was used to correct the p-values for any artificial p-value inflation due to multiple testing. 

For every of the individual factors in the BDL data set an ANOVA was calculated. Dimension reduction of the BDL data set was than performed by filtering out factors which did not significantly changing over time.

The `BDLdata` data set is reshaped into matrix format for the ANOVA calculation, with time points in rows and repeats as columns for every factor. 
```{r BDLmatrix}
BDLmatrices <- bdl_matrix_data(BDLdata, BDLsamples)
```

The following shows the ANOVA calculation for a single factor, here for `bilirubin`. 
``` {r singleanova}
  # example ANOVA for one factor
  mat.anova <- t(BDLmatrices[['bilirubin']])
  colnames(mat.anova) <- levels(BDLsamples$time_fac)

  # show data matrix
  print(mat.anova)
  
  # concatenate the data rows of df1 into a single vector r .
  r = c(t(as.matrix(mat.anova)))  # response data 
  
  # assign new variables for the treatment levels and number of observations.
  f = levels(BDLsamples$time_fac)   # treatment levels 
  k = 8                          # number of treatment levels 
  n = 5                          # observations per treatment 
  
  # create a vector of treatment factors that corresponds to each element of r in step 3 with the gl function.
  tm <- gl(k, 1, n*k, factor(f))   # matching treatments 
  
  # apply the function aov to a formula that describes the response r by the treatment factor tm.
  # fit an analysis of variance model
  av <- aov(r ~ tm) 
  
  # print out the ANOVA table with the summary function. 
  summary(av)
  # print the corresponding p-value
  p.value <- summary(av)[[1]][["Pr(>F)"]][[1]]
```

## ANOVA for all factors
Analog to the single factor ANOVA, the ANOVA is performed on all the factors. Hereby, a multitude of tests are performed, namely an ANOVA for every single factor. Consequently, the reported p-values of the ANOVA have to be adjusted via multiple testing procedures. Using the p.adjust function which given a set of p-values, returns p-values adjusted using one of several methods. The Bonferroni, Holm, Hochberg, Hommel are designed to give strong control of the family-wise error rate. We used the Holm's method for adjustment (*Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics 6, 65-70.*).

Calculation of ANOVA for all factors
```{r ANOVA}
df.anova <- all_factor_anova()
df.anova$sig <- sapply(df.anova$p.value, significant_code)  # add significant codes

df.anova$p.holm <- p.adjust(df.anova$p.value, method ="holm" , n = length(df.anova$p.value))
df.anova$sig.holm <- sapply(df.anova$p.holm, significant_code) 

# order the results py the adjusted p-values
df.anova.ordered <- df.anova[with(df.anova, order(p.holm)), ]
df.anova.ordered

# save the results
write.table(df.anova.ordered, file=file.path(resultsPath, 'BDLanova.csv'), sep="\t", quote=FALSE)
BDLanova <- df.anova
save(df.anova, file=file.path(resultsPath, "BDLanova.Rdata"))
```

## Filter factors
The factors are filtered based on the respective acceptance level, with the cutoff for the adjusted p-value being $p_{accept}$, i.e. all factors with a ANOVA with $p_{adjusted} \ge p_{accept}$ are filtered out. The filtered raw data is available as `BDLdata.fil`, the filtered mean data set as `BDLmean.fil`. All subsequent analyses are performed on the filtered data set, which is depicted in the following heatmap
``` {r filter}
p.accept = 0.05  # acceptance level
idx.accept = (df.anova$p.holm < p.accept)  # accepted subset
# subset of filtered data
BDLdata.fil <- BDLdata[, idx.accept]
BDLmean.fil <- BDLdata[, idx.accept]

# accepted
table(df.anova$p.holm<p.accept)  # 64 rejected / 90 accepted (adjusted)

# what was filtered out
table(BDLfactors$ftype[idx.accept])
# original
table(BDLfactors$ftype)
# percentage of factors retained in data set
round(table(BDLfactors$ftype[idx.accept])/table(BDLfactors$ftype), digits = 2)
```
Almost all `Cytokines` genes are retained in the data set whereas many of the `ADME` and `Fibrosis` genes are filtered.

The heatmap of the filtered raw data is depicted in the following picture
``` {r heatmapFiltered}
dtmp <- BDLdata.fil

# create better row names
rownames(dtmp) <- paste(rownames(BDLsamples), BDLsamples$time_fac, sep=" ")
# create vectors for the horizontal and vertical lines
v_lines <- ((1:8)*5+0.5)
f_types <- c("Antibodies", "Histology", "Biochemistry", "GE_Fibrosis", "GE_Cytokines", "GE_ADME")


# define colors for type of experimentell data, i.e. factor groups
colorset <- brewer.pal(length(f_types), "Set2")
color.map <- function(factor_id) {return(colorset[ which(f_types==BDLfactors$ftype[which(BDLfactors$id==factor_id)]) ])}
factorColors <- unlist(lapply(colnames(BDLdata.fil), color.map))
```

``` {r heatmap_filtered, fig.width=10, fig.height=10, error=TRUE, htmlcap='<b>Figure Heatmap 2:</b> Plot of ANOVA filtered data set.'}
heatmap.2(t(as.matrix(dtmp)), col=colors(100), scale="row", dendrogram="none", Rowv=NULL, Colv=NULL,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8, density.info="none",
          RowSideColors=factorColors,
          add.expr=abline(v=v_lines, col="black", lwd=0.5),
          main="Heatmap of BDL time course data")
          # xlab="sample", ylab="factor")
legend("left",      # location of the legend on the heatmap plot
    inset=c(-0.03,0),
    legend = rev(f_types), # category labels
    col = rev(colorset),  # color key
    lty= 1,             # line style
    lwd = 10,            # line width
    cex = 0.7,
    bty="n"
)
```


# Correlation analysis
For the correlation analysis between factors and the subsequent cluster analysis a correlation measure for time series data {Son2008} in combination with Complete-Linkage hierarchical clustering was used. This combination of methods provided the best enrichments on gene-expression time-series in a recent comparisons of methods {Jaskowiak2014, Jaskowiak2013} testing various correlation measures and clustering algorithms. 

The calculation of correlation coefficients between factors i and j ($i,j=1, ...,N_p$) was performed using the slightly modified correlation coefficient based similarity measure developed for clustering of time-course data ($Y_{i,j}^{S2}$ and $Y_{i,j}^{R2}$) {Son2008}. $Y_{i,j}^{S2}$ and $Y_{i,j}^{R2}$ are linear combinations of (i) a classical correlation part based on Spearman correlation $S_{i,j}^{*}$ in case of $Y_{i,j}^{S2}$ or Pearson $R_{i,j}^{*}$ in case of $Y_{i,j}^{R2}$, (ii) a component $A_{i,j}^{*}$ accounting for the similarity in changes between two time courses, (iii) a component $M_{i,j}^{*}$ comparing the location of minimum and maximum values of the time course (see {Son2008} for definitions)
$$Y_{i,j}^{S2} = w_1 S_{i,j}^{*} + w_2 A{i,j}^{*} + w_3 M{i,j}^{*}$$
$$Y_{i,j}^{R2} = w_1 R_{i,j}^{*} + w_2 A{i,j}^{*} + w_3 M{i,j}^{*}$$
$R_{i,j}^{*}$ and $S_{i,j}^{*}$ are hereby calculated on the individual data points for the factors i and j, $A_{i,j}^{*}$ and $M_{i,j}^{*}$ on the mean time courses averaged over the $N_r$ repeated measurements.

In the calculation of the change component we used a Spearman correlation based measure ($A**$) instead of the originally proposed Pearson measure ($A*$) resulting in the correlation scores $Y_{i,j}^{S3}$ and $Y_{i,j}^{S3}$
$$Y_{i,j}^{S3} = w_1 S_{i,j}^{*} + w_2 A_{i,j}^{**} + w_3 M_{i,j}^{*}$$
$$Y_{i,j}^{R3} = w_1 R_{i,j}^{*} + w_2 A_{i,j}^{**} + w_3 M_{i,j}^{*}$$

Herein, $A_{i,j}**$ calculates the correlation of changes between factors i and j based on Spearman correlation analog $A_{i,j}*$ as
$$A_{i,j}^{**}=(S(d_i,d_j)+1)/2$$
$$A_{i,j}^{*}=(R(d_i,d_j)+1)/2$$
The reason for this adaption was that initial analysis showed a strong dependency of the change components on outliers.

The calculated correlation YS and YR are normalized are transformed to the range [-1, 1].
Throughout the analysis the following weights were used $w_1=0.5$, $w_2=0.3$, $w_3=0.2$.

In addition to YS3 and YR3 Pearson (R) and Spearman (S) correlations were calculated for comparison. Based on the calculated correlation matrices between factors hierarchical clustering is performed on the correlation matrices using complete linkage (hclust).

## Pearson & Spearman
In a first step Pearson $R_{i,j}$ and Spearman $S_{i,j}$ correlation was calculated for the filtered factors. 
Heatmaps of the resulting correlation matrices are depicted below with reordering of factors based on hierarchical clustering with Complete Linkage.

``` {r correlation}
# correlation matrix
suppressPackageStartupMessages(require(corrplot))
cor.pearson <- cor(BDLdata.fil, method="pearson", use="pairwise.complete.obs")
cor.spearman <- cor(BDLdata.fil, method="spearman", use="pairwise.complete.obs")

# Helper function for creating correlation plot and saving to results folder.
# TODO: update the corrplot to use the heatmap.2
f_corrplot <- function(name, data, order, folder="../results",
                       width=1600, height=1600, res=200){
  # TODO: create the plot using the heatmap.2 with color based on histopathology
  fname <- sprintf("%s_%s.png", name, order)
  col2 <- HeatmapColors()
  if (!is.null(folder)){
    png(filename=file.path(folder, "correlation", fname), width=width, height=height, res=res)  
  }
  corrplot(data, order=order, hclust.method="complete", method="color", type="full", 
           tl.cex=0.3, tl.col="black", col=col2(10))
  if (!is.null(folder)){
    invisible(dev.off())  
  }
}

# Spearman
f_corrplot("cor.spearman", data=cor.spearman, order="original", folder=resultsPath)
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=resultsPath)
# Pearson
f_corrplot("cor.pearson", data=cor.pearson, order="original", folder=resultsPath)
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=resultsPath)
```

```{r}
# Pearson correlation with hierarchical clustering
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=NULL)
```

```{r}
# Spearman correlation with hierarchical clustering
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=NULL)
```

The pearson correlation is highly sensitive to outliers (correlation between factors, but also in the changes between time points). 


## YS & YR correlation
Calculation of time-course based correlation measurements, namely ys1, ys2, ys3, yr1, yr2, yr3
In ys1, ys2, yr1, yr2 all calculations are performed on the mean time course data. The classical correlation components are replaced with the correlations calculated on the individual data points.

``` {r ys1_yr1}
# calculate ys1, yr1 on mean data, i.e. correlation part (S*), slope part (A) and min/max part (M) are all calculated on the mean data of all repeats.
# w <- list(w1=0.5, w2=0.25, w3=0.25)
w <- list(w1=0.5, w2=0.3, w3=0.2)

# calculate the YSR component matrices on the filtered data set (A, A*, A**, M, M*)
# all components are calculated on the mean data
ysr.res <- ysr.matrices(BDLmean.fil, BDLmean.time, use="pairwise.complete.obs")

# Pearson & spearman correlation on individual data points
cor.S_star <- ( cor(BDLdata.fil, method="spearman", use="pairwise.complete.obs") + 1 )/2
cor.R_star <- ( cor(BDLdata.fil, method="pearson", use="pairwise.complete.obs") + 1 )/2

# Calculate the ys(1,2,3) and yr(1,2,3) with single time point correlation for
# Spearman, respectively Pearson (instead of mean)
# Takes the individual correlation, slope and min/max components for the respective
# score parts and weights with the provided weighting factors (w1,w2,w3)
cor.ys1.raw <- w$w1*cor.S_star + w$w2*ysr.res$A       + w$w3*ysr.res$M
cor.ys2.raw <- w$w1*cor.S_star + w$w2*ysr.res$A_star  + w$w3*ysr.res$M_star
cor.yr1.raw <- w$w1*cor.R_star + w$w2*ysr.res$A       + w$w3*ysr.res$M
cor.yr2.raw <- w$w1*cor.R_star + w$w2*ysr.res$A_star  + w$w3*ysr.res$M_star
# extended
cor.ys3.raw <- w$w1*cor.S_star + w$w2*ysr.res$A_star2 + w$w3*ysr.res$M_star
cor.yr3.raw <- w$w1*cor.R_star + w$w2*ysr.res$A_star2 + w$w3*ysr.res$M_star 

# scaling of correlation coefficient in interval [-1,1]
cor.ys1 <- 2*(cor.ys1.raw-0.5)
cor.ys2 <- 2*(cor.ys2.raw-0.5)
cor.ys3 <- 2*(cor.ys3.raw-0.5)
cor.yr1 <- 2*(cor.yr1.raw-0.5)
cor.yr2 <- 2*(cor.yr2.raw-0.5)
cor.yr3 <- 2*(cor.yr3.raw-0.5)

# plot subset for further analysis
f_corrplot("cor.ys3", data=cor.ys2, order="hclust", folder=NULL)

# and create all files on disk
f_corrplot("cor.ys1", data=cor.ys1, order="hclust", folder=resultsPath)
f_corrplot("cor.ys2", data=cor.ys2, order="hclust", folder=resultsPath)
f_corrplot("cor.ys3", data=cor.ys3, order="hclust", folder=resultsPath)
f_corrplot("cor.yr1", data=cor.yr1, order="hclust", folder=resultsPath)
f_corrplot("cor.yr2", data=cor.yr2, order="hclust", folder=resultsPath)
f_corrplot("cor.yr3", data=cor.yr3, order="hclust", folder=resultsPath)

```

# Hierarchical clustering
The next step of dimension reduction is clustering of the correlation matrix. This groups the factors into sets with the correlation within sets being larger than between sets. This effectivly finds groups of factors which have similar time courses.

The hclust function in R was used for clustering with complete linkage method for hierarchical clustering. This particular clustering method defines the cluster distance between two clusters to be the maximum distance between their individual components.

An overview of the clusters is given in the `results/cluster` folder.

``` {r}
# Plot the clusters
suppressPackageStartupMessages(require('matrixStats'))

# mean plots for clusters 
f_normalize_centering <- function(a){
  a.norm <- (a - mean(a))/(max(a, na.rm=TRUE) - min(a, na.rm=TRUE))
  return(a.norm)
}

# plot of mean clusters
plot_clusters <- function(method, folder=NULL){  
  # create the figure
  if (!is.null(folder)){
    fname <- sprintf("%s_cluster_overview.png", method)
    path <- file.path(folder, 'cluster', fname)
    png(filename=path, width=1600, height=1600, res=200)
  }
  # par(mfrow=c(ceiling(sqrt(Ngroups)),ceiling(sqrt(Ngroups))))
  par(mfrow=c(2,3))
  
  steps <- 1:8 # time points
    for (k in 1:Ngroups){
      g <- groups.hc.order[groups.hc.order==k]
      N <- ceiling(sqrt(length(g)))
      dgroup <- BDLmean[names(g)]
    
      # centralize and normalize columns, i.e. the individual factors for comparison
      dgroup.norm <- apply(dgroup, 2, f_normalize_centering)
      
      # mean and sd for timepoints 
      g.mean <- rowMeans(dgroup.norm)
      g.sd <- rowSds(dgroup.norm)   # apply(dgroup.norm, 2, sd)
      
      # plot sd range
      plot(1, type="n", xlab="", ylab="", xlim=c(1, 8), ylim=c(-1, 1), main=sprintf("%s : Cluster %s", method, k))
      polygon(c(steps, rev(steps)), c(g.mean+g.sd, rev(g.mean-g.sd)),
              col = rgb(0.5,0.5,0.5,0.5), border = NA)
      
      # individual data
      for (name in names(g)){
        points(steps, dgroup.norm[, name], pch=16, col="black")
        lines(steps, dgroup.norm[, name], col=rgb(0.5,0.5,0.5, 0.8), lwd=1)
      }
      # mean over factors in cluster
      lines(steps, g.mean, col="blue", lwd=2)
    }
    par(mfrow=c(1,1))
  if (!is.null(folder)){
    invisible(dev.off())
  }
}

# Plot individual time courses in cluster
plot_clusters_items <- function(folder=NULL){
  for (k in 1:Ngroups){
    if (!is.null(folder)){
      fname <- sprintf("%s_cluster_%s.png", method, k)
      path <- file.path(folder, 'cluster', fname)
      png(filename=path, width=3000, height=3000, res=200)  
    }
    g <- groups.hc.order[groups.hc.order==k]
    N <- ceiling(sqrt(length(g)))
    par(mfrow=c(N,N))
    for (name in names(g)){
      plot_single(name_A=name) 
    }
    par(mfrow=c(1,1))  
    if (!is.null(folder)){
      invisible(dev.off())
    }
  }  
}

correlation_matrix_for_method <- function(method){
   if (identical(method, "ys1")){
    cor.cluster <- cor.ys1  
  }else if (identical(method, "ys2")){
    cor.cluster <- cor.ys2
  }else if (identical(method, "ys3")){
    cor.cluster <- cor.ys3
  }else if (identical(method, "yr1")){
    cor.cluster <- cor.yr1
  }else if (identical(method, "yr2")){
    cor.cluster <- cor.yr2
  }else if (identical(method, "yr3")){
    cor.cluster <- cor.yr3
  }else if (identical(method, "pearson")){
    cor.cluster <- cor.pearson
  }else if (identical(method, "spearman")){
    cor.cluster <- cor.spearman
  }  
  return(cor.cluster)
}

# apply hirarchical clustering based on selected correlation measure
cluster_methods <- c("pearson", "spearman", "ys1", "ys2", "ys3", "yr1", "yr2", "yr3")
Ngroups <-  6

for (method in cluster_methods){
  cor.cluster <- correlation_matrix_for_method(method)
  
  # perform hierarchical clustering and cut into Ngroups clusters.
  hc <- hclust(dist(cor.cluster)) 
  groups <- cutree(hc, k=Ngroups)
  groups.hc.order <- groups[hc$order]
  
  # plot cluster overview in report
  if (identical(method, "ys3")){
    plot_clusters(method=method, folder=NULL)  
  }
  # plot all clusters on disk
  plot_clusters(method=method, folder=resultsPath) 

  # plot individual factors in clusters on disk
  plot_clusters_items(folder=resultsPath)
}
```

TODO: overview over the cluster size and content




Display the clusters with the heatmap
``` {r heatmap_ys3, fig.width=10, fig.height=10, error=TRUE, htmlcap='<b>Figure Heatmap Cluster:</b> Plot of ANOVA filtered data set.'}

method <- 'ys3'
cor.cluster <- correlation_matrix_for_method(method)

col2 <- HeatmapColors()
hc <- hclust(dist(cor.cluster)) 
# get cluster IDs for the groups
groups <- cutree(hc, k=Ngroups)

# define colors for the Ngroups clusters

# display.brewer.all()
colorset <- brewer.pal(Ngroups, "Set1")
color.map <- function(cluster_id) {return(colorset[cluster_id])}
clusterColors <- unlist(lapply(groups, color.map))

heatmap.2(cor.cluster, col=col2(100), scale="none",
          key=TRUE, symkey=FALSE, trace="none", cexRow=0.5, cexCol=0.5,
          main=method,
          density.info="none", dendrogram="column", Rowv=as.dendrogram(hc), Colv=as.dendrogram(hc), keysize=0.8,
          ColSideColors=clusterColors, revC=TRUE)
```


Overview of the individual time courses in the clusters
```{r, eval=FALSE}
# test
```

# Decision Trees
The decision trees are based on the clusters. This has the large advantage to be not dependent on a single factor, but it uses the combined information available by multiple factors. Consequently, the decision tree is applicable to any subset of factors measured. 

**TODO**

