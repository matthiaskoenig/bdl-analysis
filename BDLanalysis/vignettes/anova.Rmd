---
output: html_document
---
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{BDL ANOVA}
-->
# Dimension reduction via ANOVA
Dimension reduction of the BDL data set is performed by filtering out all factors not changing significantly during the time course. For every single factor an ANOVA is calculated with subsequent filtering based on adjusted p-value (multiple testing correction by testing on all factors). The ANOVA tests if any of the time points has a significantly different mean.

Definition of paths
```{r path}
baseLoc <- system.file(package="BDLanalysis")
extPath <- file.path(baseLoc, "extdata")
resultsPath <- "/home/mkoenig/git/bdl-analysis/results"
```

## Read BDL data
First the BDL data, BDL sample definition and the fluidigm probe definitions are loaded
```{r BDLdata, eval=TRUE}
library('reshape')
library("calibrate")
library('BDLanalysis')
data(BDLdata)
data(BDLsamples)
data(BDLprobes)
```

The BDLdata set of all timecourses for the factors is reshaped into matrix form for the ANOVA calculation
```{r BDLmatrix}
BDLmatrices <- bdl_matrix_data(BDLdata, BDLsamples)
print(BDLmatrices[[1]])
```

## Perform ANOVA
Now the ANOVA is calculated for all factors and data.frame of p.values returned
```{r ANOVA}
df.anova <- all_factor_anova()  # calculate ANOVA
df.anova$sig <- sapply(df.anova$p.value, significant_code)  # add significant codes
```


## Adjust p-values for multiple testing
Using the p.adjust function which given a set of p-values, returns p-values adjusted using one of several methods. The Bonferroni, Holm, Hochberg, Hommel are designed to give strong control of the family-wise error rate. There seems no reason to use the unmodified Bonferroni correction because it is dominated by Holm's method, which is also valid under arbitrary assumptions.

The correction is performed using Holm  
> Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics 6, 65-70.

```{r}
df.anova$p.holm <- p.adjust(df.anova$p.value, method ="holm" , n = length(df.anova$p.value))
df.anova$sig.holm <- sapply(df.anova$p.holm, significant_code) 

# order the results py the adjusted p-values
df.anova.ordered <- df.anova[with(df.anova, order(p.holm)), ]
df.anova.ordered
```
Save the results
``` {r}
write.table(df.anova.ordered, file=file.path(resultsPath, 'BDLanova.csv'), sep="\t", quote=FALSE)
BDLanova <- df.anova
save(df.anova, file=file.path(resultsPath, "BDLanova.Rdata"))
```

The factors are filtered based on acceptance level, with the cutoff for the adjusted p-value being $p_{accept}$. I.e. all factors with a ANOVA with $p_{factor} \ge p_{accept}$ are filtered out. The filtered data sets are generated.
``` {r filtering}
p.accept = 0.05  # acceptance level
idx.accept = (df.anova$p.holm < p.accept)  # accepted subset
  
# accepted (TRUE/FALSE)
table(df.anova$p.holm<p.accept)  # 64 rejected / 90 accepted (adjusted)
table(df.anova$p.value>=p.accept) # 19 rejected / 135 accepted (unadjusted)
  
# subset of filtered data
BDLdata.fil <- BDLdata[, idx.accept]
BDLmean.fil <- BDLdata[, idx.accept]
```

Heatmap of the filtered BDL data.  
TODO: add the view of the Chips and histopathology
``` {r heatmapBDL, eval=FALSE}
library('ALL')
# plot of the data subset which is used for the correlation analysis
col2 <- colorRampPalette(c("#67001F", "#B2182B", "#D6604D", "#F4A582", "#FDDBC7",
                           "#FFFFFF", "#D1E5F0", "#92C5DE", "#4393C3", "#2166AC", "#053061"))
heatmap.2(t(as.matrix(BDLdata.fil)), col=col2(100), scale="row", Rowv=FALSE, Colv=FALSE,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8)

png(filename=file.path(resultsPath, "BDLdata.fil.png"), width=1600, height=1600, res=200)
heatmap.2(t(as.matrix(BDLdata.fil)), col=col2(100), scale="row", Rowv=NULL, Colv=NULL,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8)
dev.off()
```


# Correlation analysis
Correlation matrices are calculated using a modified correlation score for the analysis of time course data. Standard Pearson and Spearman scores are calculated as reference values and for comparison.  
Based on the correlation scores hierarchical clustering is performed using complete linkage (hclust).

Spearman & Pearson correlation matrices are plotted either in normal order or based on the reordering via hierarchical clustering

``` {r correlation}
# correlation matrix
require(corrplot)
cor.pearson <- cor(BDLdata.fil, method="pearson", use="pairwise.complete.obs")
cor.spearman <- cor(BDLdata.fil, method="spearman", use="pairwise.complete.obs")

# Helper function for creating correlation plot and saving to results folder.
f_corrplot <- function(name, data, order, folder="../results",
                       width=1600, height=1600, res=200){
  fname <- sprintf("%s_%s.png", name, order)
  col2 <- HeatmapColors()
  if (!is.null(folder)){
    png(filename=file.path(folder, "correlation", fname), width=width, height=height, res=res)  
  }
  corrplot(data, order=order, hclust.method="complete", method="color", type="full", 
           tl.cex=0.3, tl.col="black", col=col2(10))
  if (!is.null(folder)){
    invisible(dev.off())  
  }
}

# Spearman
f_corrplot("cor.spearman", data=cor.spearman, order="original", folder=resultsPath)
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=resultsPath)
# Pearson
f_corrplot("cor.pearson", data=cor.pearson, order="original", folder=resultsPath)
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=resultsPath)
```

```{r, out.width = '1600px', out.height = '1600px'}
# Spearman correlation with hierarchical clustering
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=NULL)
```

```{r, out.width = '1600px', out.height = '1600px'}
# Pearson correlation with hierarchical clustering
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=NULL)
```
