---
title: "Statistical analysis for BDL mice"
output:
  html_document: default
  pdf_document:
    keep_tex: yes
header-includes: \usepackage{graphicx}
---
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{BDL raw data processing}
-->

# BDL Analysis

This script contains the complete statistical analysis for the publication Pathobiochemical signatures of cholestatic liver disease in bile duct ligated mice (BMC Systems Biology).
Main steps in the analysis are
#    The analysis consists of regression analysis of the various measured factors based
#    on different measures.
#    - Pearson Correlation 
#    - Spearman Correlation
#    - YS1 and YR1 (time course correlation)


```{r path}
baseLoc <- system.file(package="BDLanalysis")
extPath <- file.path(baseLoc, "extdata")
resultsPath <- "/home/mkoenig/git/bdl-analysis/results"
```

## Read BDL data
The BDL data, BDL sample definition and the Fluidigm probe definitions are loaded via
```{r BDLdata, eval=TRUE}
library("calibrate")
library('BDLanalysis')
data(BDLdata)
data(BDLsamples)
data(BDLprobes)
```

Calculation of mean timecourse for factors averaged over the 5 repeats.
```{r BDLmean}
BDLmean <- bdl_mean_data(BDLdata, BDLsamples)
BDLmean.time <- as.numeric(levels(as.factor(BDLsamples$time)))
```

Create overview plots for all individual factors. These are stored in the
resultsPath folder.
```{r factorPlots, eval=FALSE}
# Single factor visualization
plot_single_factor(name=colnames(BDLdata)[2])

# Creates plots of all factors in BDLdata
plot_all_factors(path=resultsPath)
```


## Actb controls
Actb was measured on all Fluidigm chips and serves as quality control of the measurement/correlation analysis. The pairwise correlation between all Actb measurements should result in high correlation values
```{r CheckActB}
# Actb control figure
png(filename=file.path(resultsPath, "Actb_control.png"), width=1600, height=600, res=200)
par(mfrow=c(1,3))
plot_cor_pair("Actb", "Actb.x", single_plots=FALSE)
plot_cor_pair("Actb", "Actb.y", single_plots=FALSE)
plot_cor_pair("Actb.x", "Actb.y", single_plots=FALSE)
par(mfrow=c(1,1))
dev.off()

# calculate the correlations
plot_single("Actb")
plot_single_factor("Actb", path=NULL)
plot_single("Actb.x")
plot_single("Actb.y")
plot_cor_pair("Actb", "Actb.x", single_plots=FALSE)
plot_cor_pair("Actb", "Actb.y", single_plots=FALSE)
plot_cor_pair("Actb.x", "Actb.y", single_plots=FALSE)

# calculate Spearman and Pearson correlation coefficients on mean and individual
# data
actb.spearman <- cor(data.frame(Actb=BDLdata$Actb, 
                                Actb.x=BDLdata$Actb.x, 
                                Actb.y=BDLdata$Actb.y), method="spearman")

actb.spearman.mean <- cor(data.frame(Actb=BDLmean$Actb, 
                                     Actb.x=BDLmean$Actb.x, 
                                     Actb.y=BDLmean$Actb.y), method="spearman")

actb.pearson <- cor(data.frame(Actb=BDLdata$Actb, 
                               Actb.x=BDLdata$Actb.x, 
                               Actb.y=BDLdata$Actb.y), method="pearson")

actb.pearson.mean <- cor(data.frame(Actb=BDLmean$Actb, 
                                    Actb.x=BDLmean$Actb.x, 
                                    Actb.y=BDLmean$Actb.y), method="pearson")
print(actb.spearman)
print(actb.spearman.mean)
print(actb.pearson)
print(actb.pearson.mean)
```

Heatmap of the full data set provides an overview over the data quality
```{r heatmap, fig.width=10, fig.height=10, error=TRUE}
library("gplots")
colors <- HeatmapColors() 
heatmap.2(t(as.matrix(BDLdata)), col=colors(100), scale="row", Rowv=NULL, Colv=NULL,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8)
```

# Read BDL data
The BDLdata set of all timecourses for the factors is reshaped into matrix form for the ANOVA calculation
```{r BDLmatrix}
BDLmatrices <- bdl_matrix_data(BDLdata, BDLsamples)
print(BDLmatrices[[1]])
```

# Dimension reduction via ANOVA
A one-way analysis of variance (ANOVA) was applied to isolate factors showing significant ($p_{adjusted}< 0.05$) up- or down-regulation during the time course, using the Holm's procedure to correct for any artificial p-value inflation. In its simplest form, ANOVA provides a statistical test of whether or not the means of several groups are equal, and therefore generalizes the t-test to more than two groups, with the groups being the sampled time points. For every of the individual factors in the BDL data set an ANOVA was calculated.Dimension reduction of the BDL data set was than performed by filtering out factors which did not significantly changing over time.

An ANOVA is calculated for all factors (N=`r nrow(BDLdata)`). A data.frame with the p-values of the ANOVA is returned which is used for filtering the BDL data set. Significance codes are added for visual inspection.


## Adjust p-values for multiple testing
A multitude of tests were performed, namely an ANOVA for every single factor. Consequently, the reported p-values of the ANOVA have to be adjusted via multiple testing procedures. Using the p.adjust function which given a set of p-values, returns p-values adjusted using one of several methods. The Bonferroni, Holm, Hochberg, Hommel are designed to give strong control of the family-wise error rate. There seems no reason to use the unmodified Bonferroni correction because it is dominated by Holm's method, which is also valid under arbitrary assumptions.

The correction is performed using Holm  

> Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics 6, 65-70.

# TODO: Add the code for single factor ANOVA


The ANOVA is now calculated for every single factor
```{r ANOVA}
df.anova <- all_factor_anova()
df.anova$sig <- sapply(df.anova$p.value, significant_code)  # add significant codes

df.anova$p.holm <- p.adjust(df.anova$p.value, method ="holm" , n = length(df.anova$p.value))
df.anova$sig.holm <- sapply(df.anova$p.holm, significant_code) 

# order the results py the adjusted p-values
df.anova.ordered <- df.anova[with(df.anova, order(p.holm)), ]
df.anova.ordered

# save the results
write.table(df.anova.ordered, file=file.path(resultsPath, 'BDLanova.csv'), sep="\t", quote=FALSE)
BDLanova <- df.anova
save(df.anova, file=file.path(resultsPath, "BDLanova.Rdata"))
```

## Filter factors
The factors are filtered based on acceptance level, with the cutoff for the adjusted p-value being $p_{accept}$. I.e. all factors with a ANOVA with $p_{adjusted} \ge p_{accept}$ are filtered out. The filtered data sets are generated.
``` {r filter}
p.accept = 0.05  # acceptance level
idx.accept = (df.anova$p.holm < p.accept)  # accepted subset
  
# accepted
table(df.anova$p.holm<p.accept)  # 64 rejected / 90 accepted (adjusted)
table(df.anova$p.value<p.accept) # 19 rejected / 135 accepted (unadjusted)
  
# subset of filtered data
BDLdata.fil <- BDLdata[, idx.accept]
BDLmean.fil <- BDLdata[, idx.accept]
```

Heatmap of the filtered BDL data.  
TODO: add the view of the Chips and histopathology
``` {r heatmapBDL, error=TRUE}
library('ALL')
# plot of the data subset which is used for the correlation analysis
col2 <- colorRampPalette(c("#67001F", "#B2182B", "#D6604D", "#F4A582", "#FDDBC7",
                           "#FFFFFF", "#D1E5F0", "#92C5DE", "#4393C3", "#2166AC", "#053061"))
heatmap.2(t(as.matrix(BDLdata.fil)), col=col2(100), scale="row", Rowv=FALSE, Colv=FALSE,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8)

png(filename=file.path(resultsPath, "BDLdata.fil.png"), width=1600, height=1600, res=200)
heatmap.2(t(as.matrix(BDLdata.fil)), col=col2(100), scale="row", Rowv=NULL, Colv=NULL,
          key=TRUE, trace="none", cexRow=0.5, keysize=0.8)
dev.off()
```

# Correlation analysis
The correlation and cluster analysis uses a correlation measure for time series data in combination with Complete-Linkage hierarchical clustering, which provided the best enrichments on gene-expression time-series in a recent comparisons of methods {Jaskowiak2014, Jaskowiak2013}. The time-course experiment includes $n=8$ time points denoted by $t_1,..., t_n$ consisting of a total $p=154$ factors, with $N=5$ repeats per time point. Correlation analysis between factors i and j (i,j=1, â€¦,p) was performed using a modified correlation coefficient based similarity measure developed for clustering of time-course data ($Y_{i,j}^{S2}$ and $Y_{i,j}^{R2}$) {Son2008}. Yi,jS2and Yi,jR2 are linear combinations of a classical correlation part Ri,j*(Pearson) or Si,j*(Spearman), a component Ai,j*accounting for the similarity in changes between the time courses and a component Mi,j* comparing the location of minimum and maximum
Yi,jS2=1Si,j*+1A<i>,<j>*+2M<i>,<j>*
Yi,jR2=1Ri,j*+1A<i>,<j>*+2M<i>,<j>*
with Ri,j*and Si,j*being calculated on the individual data for factor i and j, A<i>,<j>*and M<i>,<j>*on the mean time courses <i>, <j> averaged over the N replicates.Yi,jS2and Yi,jR2were extended in a simple manner to account for the non-equidistant time points t1,..., tn=0h, 6h, 12h, 18h, 30h, 2d, 5d, 14d in the study design
Yi,jS3=1Si,j*+1A<i>,<j>**+2M<i>,<j>**
Yi,jR3=1Ri,j*+1A<i>,<j>**+2M<i>,<j>**
Herein, Ai,j**calculates the correlation of slopes analogue to the correlation in distances in Ai,j* between factors i and j 
Ai,j**=(Pearson correlation(si,sj)+1)/2
with si=(si1,si2,...,si(n-1)) being the vector of slopes sik=s(i,tk,tk+1) = xi,tk+1- xi,tktk+1-tk
Mi,j**calculates the absolute distance in maximum and minimum times instead of the distance of indices in Mi,j*
Mi,j**=1-|timin-tjmin|+|timax-tjmax|2(tn-t0)
Throughout the analysis the weights were 
For comparison Pearson, Spearman and YS2 and YR2 correlation coefficients were calculated.
See Supporting Information for details.
All computations were performed in R with all source code and data provided in the supplement.




Correlation matrices are calculated using a modified correlation score for the analysis of time course data. Standard Pearson and Spearman scores are calculated as reference values and for comparison.  
Based on the correlation scores hierarchical clustering is performed using complete linkage (hclust).

Spearman & Pearson correlation matrices are plotted either in normal order or based on the reordering via hierarchical clustering

``` {r correlation}
# correlation matrix
require(corrplot)
cor.pearson <- cor(BDLdata.fil, method="pearson", use="pairwise.complete.obs")
cor.spearman <- cor(BDLdata.fil, method="spearman", use="pairwise.complete.obs")

# Helper function for creating correlation plot and saving to results folder.
f_corrplot <- function(name, data, order, folder="../results",
                       width=1600, height=1600, res=200){
  fname <- sprintf("%s_%s.png", name, order)
  col2 <- HeatmapColors()
  if (!is.null(folder)){
    png(filename=file.path(folder, "correlation", fname), width=width, height=height, res=res)  
  }
  corrplot(data, order=order, hclust.method="complete", method="color", type="full", 
           tl.cex=0.3, tl.col="black", col=col2(10))
  if (!is.null(folder)){
    invisible(dev.off())  
  }
}

# Spearman
f_corrplot("cor.spearman", data=cor.spearman, order="original", folder=resultsPath)
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=resultsPath)
# Pearson
f_corrplot("cor.pearson", data=cor.pearson, order="original", folder=resultsPath)
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=resultsPath)
```

```{r, out.width = '1200px', out.height = '1200px'}
# Spearman correlation with hierarchical clustering
f_corrplot("cor.spearman", data=cor.spearman, order="hclust", folder=NULL)
```

```{r, out.width = '1200px', out.height = '1200px'}
# Pearson correlation with hierarchical clustering
f_corrplot("cor.pearson", data=cor.pearson, order="hclust", folder=NULL)
```

# YS and YR correlation
Calculation of time-course based correlation measurements, namely ys1, ys2, ys3, yr1, yr2, yr3
In ys1, ys2, yr1, yr2 all calculations are performed on the mean time course data. The classical correlation components are replaced with the correlations calculated on the individual data points.

``` {r ys1_yr1}
# calculate ys1, yr1 on mean data, i.e. correlation part (S*), slope part (A) and min/max part (M) are all calculated on the mean data of all repeats.
w <- list(w1=0.5, w2=0.25, w3=0.25)
ys1.mean <- ys1.df(BDLmean.fil, BDLmean.time, w1=w$w1, w2=w$w2, w3=w$w3, use="pairwise.complete.obs")
ys2.mean <- ys2.df(BDLmean.fil, BDLmean.time, w1=w$w1, w2=w$w2, w3=w$w3, use="pairwise.complete.obs")

# scaling to interval [-1, 1]
# The dimensions correspond to the filtered dataset
cor.ys1.mean <- 2*(ys1.mean$value - 0.5)  
cor.ys2.mean <- 2*(ys2.mean$value - 0.5)

# Pearson & spearman correlation on full dataset as replacement for the 
# mean Pearson/Spearman in ys1, ys2, yr1, yr2
# Now calculate the scores with full correlation
cor.S_star <- ( cor(BDLmean.fil, method="spearman", use="pairwise.complete.obs") + 1 )/2
cor.R_star <- ( cor(BDLmean.fil, method="pearson", use="pairwise.complete.obs") + 1 )/2

# Calculate the ys(1,2,3) and yr(1,2,3) with single time point correlation for
# Spearman, respectively Pearson (instead of mean)
# Takes the individual correlation, slope and min/max components for the respective
# score parts and weights with the provided weighting factors (w1,w2,w3)
cor.ys1.raw <- w$w1*cor.S_star + w$w2*ys1.mean$A + w$w3*ys1.mean$M
cor.ys2.raw <- w$w1*cor.S_star + w$w2*ys2.mean$A_star + w$w3*ys2.mean$M_star

# considering slope and time difference
cor.ys3.raw <- w$w1*cor.S_star + w$w2*ys2.mean$A_star2 + w$w3*ys2.mean$M_star2

cor.yr1.raw <- w$w1*cor.R_star + w$w2*ys1.mean$A + w$w3*ys1.mean$M
cor.yr2.raw <- w$w1*cor.R_star + w$w2*ys2.mean$A_star + w$w3*ys2.mean$M_star
# considering slope and time difference
cor.yr3.raw <- w$w1*cor.R_star + w$w2*ys2.mean$A_star2 + w$w3*ys2.mean$M_star2

# scaling of correlation coefficient in interval [-1,1]
cor.ys1 <- 2*(cor.ys1.raw-0.5)
cor.ys2 <- 2*(cor.ys2.raw-0.5)
cor.ys3 <- 2*(cor.ys3.raw-0.5)
cor.yr1 <- 2*(cor.yr1.raw-0.5)
cor.yr2 <- 2*(cor.yr2.raw-0.5)
cor.yr3 <- 2*(cor.yr3.raw-0.5)

# plot clustered results in report
f_corrplot("cor.ys1", data=cor.ys1, order="hclust", folder=NULL)
f_corrplot("cor.ys2", data=cor.ys2, order="hclust", folder=NULL)
f_corrplot("cor.ys3", data=cor.ys3, order="hclust", folder=NULL)
f_corrplot("cor.yr1", data=cor.yr1, order="hclust", folder=NULL)
f_corrplot("cor.yr2", data=cor.yr2, order="hclust", folder=NULL)
f_corrplot("cor.yr3", data=cor.yr3, order="hclust", folder=NULL)
# and on disk
f_corrplot("cor.ys1", data=cor.ys1, order="hclust", folder=resultsPath)
f_corrplot("cor.ys2", data=cor.ys2, order="hclust", folder=resultsPath)
f_corrplot("cor.ys3", data=cor.ys3, order="hclust", folder=resultsPath)
f_corrplot("cor.yr1", data=cor.yr1, order="hclust", folder=resultsPath)
f_corrplot("cor.yr2", data=cor.yr2, order="hclust", folder=resultsPath)
f_corrplot("cor.yr3", data=cor.yr3, order="hclust", folder=resultsPath)


# extreme example where the difference between pearson and spearman matters
plot_cor_pair("Nos2", "Cxcl15")
plot_cor_pair("albumin", "Cyp2b10")
```


